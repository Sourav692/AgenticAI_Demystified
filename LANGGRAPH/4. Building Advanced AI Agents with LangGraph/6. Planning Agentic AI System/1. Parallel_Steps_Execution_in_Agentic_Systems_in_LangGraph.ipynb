{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d580737f-64de-4aee-a3e6-1f8c34ecaf8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "f4169bfb-769a-4db3-833e-c827f19024b2"
   },
   "source": [
    "# Parallel Steps Execution in Agentic Systems in LangGraph\n",
    "\n",
    "\n",
    "LangGraph provides robust support for parallel execution of nodes, enhancing the efficiency and performance of graph-based agentic workflows.\n",
    "\n",
    "This parallelization is achieved through fan-out and fan-in mechanisms, and can utilize standard edges or conditional edges.\n",
    "\n",
    "\n",
    "![](https://i.imgur.com/t44twOn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1d52d5cc-7fc9-413a-acc8-d1b4327b3054",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9hEI3WL328vZ"
   },
   "source": [
    "## Install OpenAI, LangGraph and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "17d3a226-996e-4684-89e5-5bfd3929880d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "618eab5c-4ef7-4273-8e0b-a9c847897ed7",
    "outputId": "70712460-6a27-436a-e35c-8f3d7a0d9135"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.14\n",
    "!pip install langchain-openai==0.3.0\n",
    "!pip install langchain-community==0.3.14\n",
    "!pip install langgraph==0.2.64\n",
    "!pip install wikipedia==1.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cf7db3e-ce8b-488a-91bf-9273c0596936",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3038bf18-b69f-429b-871f-0b2874c63dc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04eaa3f6-59ef-49e3-a731-8d8590a1849f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "73841be0-11b0-4ed4-da9b-aff8e5ba25b9"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7acec8a2-b715-4ca7-ad84-76b8d0284494",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d2e154e9-1cc4-447c-85aa-23f05c940d4a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "df2110bd-50e1-41f8-c9fd-47cf573eadad"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33cf9936-dd4b-448e-9c0f-9cd72f3b9fa9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8907db01-465b-4032-8517-c9a4790e20c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "845ac2de-7a4d-4e8e-90bb-822b97add2c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "_O8XqQ7QHhbc"
   },
   "source": [
    "## Simple Linear AI Workflow\n",
    "\n",
    "Here we have a simple AI workflow which has a few sequential steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8d03273-ab2d-41fc-96ff-ba6abc7aa191",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "1dd77093-1794-4bd7-8c57-58f59a74c20b",
    "outputId": "f11937ce-4a94-42fe-dd48-35db3ced2fbe"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "from typing import Any\n",
    "from typing_extensions import TypedDict\n",
    "from typing import Annotated\n",
    "import operator\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "\n",
    "class State(TypedDict):\n",
    "    # The operator.add reducer fn makes this append-only\n",
    "    state: Annotated[list, operator.add]\n",
    "\n",
    "class ReturnNodeValue:\n",
    "    def __init__(self, node_secret: str):\n",
    "        self._value = node_secret\n",
    "\n",
    "    def __call__(self, state: State) -> Any:\n",
    "        print(f\"Adding {self._value} to {state['state']}\")\n",
    "        return {\"state\": [self._value]}\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret\n",
    "builder.add_node(\"a\", ReturnNodeValue(\"step A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"step B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"step C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"step D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"b\", \"c\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e009c681-fc7a-4b6f-96ac-4634d4371eca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bdd027d3-ef9f-4d43-b190-e9f07d521e18"
   },
   "source": [
    "We over-write state, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "42857d30-7bf2-4ad4-9772-c74e2e598b23",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf260088-90d5-45b2-93ab-42f241560840",
    "outputId": "f7440d93-9edc-40e3-89ba-2d54b6a3b2fe"
   },
   "outputs": [],
   "source": [
    "graph.invoke({\"state\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8b4bd106-3965-49c8-842e-342f5ba98356",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "nYbYf-83HIV7"
   },
   "source": [
    "## Simple Linear AI Workflow with parallel steps\n",
    "\n",
    "Key Concepts:\n",
    "- Fan-Out: A process where a single node branches out to multiple nodes, allowing simultaneous execution of tasks. (Like a router node in router agents)\n",
    "- Fan-In: A process where multiple nodes converge back into a single node, aggregating the results from parallel tasks.\n",
    "\n",
    "Here we have a simple AI workflow which has a few parallel steps\n",
    "\n",
    "We will run b and c in parallel and then run d.\n",
    "\n",
    "We can do this easily with fan-out from a to b and c, and then fan-in to d.\n",
    "\n",
    "The the state updates are applied at the end of each step.\n",
    "\n",
    "When using fan out, we need to be sure that we are using a reducer if steps are writing to the same the channel / key.\n",
    "\n",
    "When `operator.add` is applied to lists, it performs list concatenation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ee0b4fcc-7860-4514-b060-405d300f3dbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "8f1292ac-510a-4801-b2a3-e2c6d2d9582a",
    "outputId": "5b85334a-6d12-49db-f675-81ac8c17f4de"
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "from typing import Annotated\n",
    "\n",
    "class State(TypedDict):\n",
    "    # The operator.add reducer fn makes this append-only\n",
    "    state: Annotated[list, operator.add]\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret\n",
    "builder.add_node(\"a\", ReturnNodeValue(\"step A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"step B\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"step C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"step D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "# fan out\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "# fan in\n",
    "builder.add_edge(\"b\", \"d\")\n",
    "builder.add_edge(\"c\", \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "662d57ee-fc9e-4bf8-9866-91d5492fe15d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ffbad231-fc1d-49b1-a9fc-ed9153fa3977",
    "outputId": "71950351-08c8-4cce-d3cf-568b9f460265"
   },
   "outputs": [],
   "source": [
    "graph.invoke({\"state\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "54f5026a-f8c2-4d19-be7e-0d9cec78376c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "bdf5baa2-cecd-44b6-b0c4-d258340783f8"
   },
   "source": [
    "Now we see that we append to state for the updates made in parallel by `b` and `c`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "aec500c5-5193-4306-8aae-1e7dc7d51b08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ed6fc7c7-198d-41be-867f-e77c93ba3217"
   },
   "source": [
    "## Parallel AI Workflow with multiple steps\n",
    "\n",
    "Now, lets consider a case where one parallel path has more steps than the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "abb4520b-b0d0-4ea6-b3d6-7af117ce5061",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "f50b5d4f-dd39-4c22-b623-e0abc23f9144",
    "outputId": "f73fec11-b64e-4176-97cf-bdeb0425ae49"
   },
   "outputs": [],
   "source": [
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret\n",
    "builder.add_node(\"a\", ReturnNodeValue(\"step A\"))\n",
    "builder.add_node(\"b\", ReturnNodeValue(\"step B\"))\n",
    "builder.add_node(\"x\", ReturnNodeValue(\"step X\"))\n",
    "builder.add_node(\"c\", ReturnNodeValue(\"step C\"))\n",
    "builder.add_node(\"d\", ReturnNodeValue(\"step D\"))\n",
    "\n",
    "# Flow\n",
    "builder.add_edge(START, \"a\")\n",
    "# fan out\n",
    "builder.add_edge(\"a\", \"b\")\n",
    "builder.add_edge(\"a\", \"c\")\n",
    "builder.add_edge(\"b\", \"x\")\n",
    "# fan in\n",
    "builder.add_edge([\"x\", \"c\"], \"d\")\n",
    "builder.add_edge(\"d\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bf32833f-93b2-4792-b3e9-d901b3dcc5d4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "11640e6f-ac62-4ad4-89d9-7f6f9b56bf7a"
   },
   "source": [
    "In this case, `b`, `x`, and `c` are all part of the same step.\n",
    "\n",
    "The graph will wait for all of these to be completed before proceeding to step `d`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "af73fc2f-ef1c-4096-af4f-8b3b96076b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fafda930-e75b-410f-ba93-eb5fc0219303",
    "outputId": "f557d6a0-9a13-4d64-96d8-a6af2784c14b"
   },
   "outputs": [],
   "source": [
    "graph.invoke({\"state\": []})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08b7d5d5-c1c6-4261-9547-4742cf5b203f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "34e0750b-e6af-40d9-835c-c664da5a2d3b"
   },
   "source": [
    "## Working with LLMs\n",
    "\n",
    "Now, lets add a realistic example!\n",
    "\n",
    "We want to gather context from two external sources (Wikipedia and Web-Seach) and have an LLM answer a question.\n",
    "\n",
    "![](https://i.imgur.com/t44twOn.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a978c42a-68f2-49bf-92cf-2501a374ad89",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "W21ZDORCQhCa"
   },
   "source": [
    "### Define Agent State Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7cfce08f-ec6a-4e92-a666-ab54ab1a94ff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "e1e9d03c-cb41-415c-862d-c9616d5a2d07"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4940833b-5d25-40d8-a7e4-1865732a41e1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0f75cc78-d1a1-47a5-8648-bf5a79c883de"
   },
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    answer: str\n",
    "    context: Annotated[list, operator.add]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e2b77a56-d368-4f0a-8930-805f1425f50e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9e714ea8-095c-461a-98bc-ee782a84ef5c"
   },
   "source": [
    "### Define Node functions and Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e9cdc8-a858-4ac2-a53d-6693ceb799e3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "bfb4f56c-3334-4927-8ed8-62fd384ee43e",
    "outputId": "d10ba52e-15d1-4339-d2b9-2282d2cdd021"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "from langchain_community.tools import TavilySearchResults\n",
    "\n",
    "def search_web(state):\n",
    "\n",
    "    \"\"\" Retrieve docs from web search \"\"\"\n",
    "    print('--Getting Info from the Web--')\n",
    "\n",
    "    # Search\n",
    "    tavily_search = TavilySearchResults(max_results=3)\n",
    "    search_docs = tavily_search.invoke(state['question'])\n",
    "\n",
    "     # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'''Content: {doc['content']}\\nSource: {doc['url']}'''\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "def search_wikipedia(state):\n",
    "\n",
    "    \"\"\" Retrieve docs from wikipedia \"\"\"\n",
    "    print('--Getting Info from the Wikipedia--')\n",
    "\n",
    "    # Search\n",
    "    search_docs = WikipediaLoader(query=state['question'],\n",
    "                                  load_max_docs=2).load()\n",
    "\n",
    "     # Format\n",
    "    formatted_search_docs = \"\\n\\n---\\n\\n\".join(\n",
    "        [\n",
    "            f'''Content: {doc.page_content}\\nSource: {doc.metadata[\"source\"]}'''\n",
    "            for doc in search_docs\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return {\"context\": [formatted_search_docs]}\n",
    "\n",
    "def generate_answer(state):\n",
    "\n",
    "    \"\"\" Node to answer a question \"\"\"\n",
    "    print('--Generating final answer--')\n",
    "\n",
    "    # Get state\n",
    "    context = state[\"context\"]\n",
    "    question = state[\"question\"]\n",
    "\n",
    "    # Template\n",
    "    answer_template = \"\"\"Answer the question {question}\n",
    "                         using these context documents: {context}\"\"\"\n",
    "    answer_instructions = answer_template.format(question=question,\n",
    "                                                       context=context)\n",
    "\n",
    "    # Answer\n",
    "    answer = llm.invoke([SystemMessage(content=answer_instructions)]+[HumanMessage(content=f\"Answer the question.\")])\n",
    "\n",
    "    # Append it to state\n",
    "    return {\"answer\": answer}\n",
    "\n",
    "# Add nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Initialize each node with node_secret\n",
    "builder.add_node(\"search_web\",search_web)\n",
    "builder.add_node(\"search_wikipedia\", search_wikipedia)\n",
    "builder.add_node(\"generate_answer\", generate_answer)\n",
    "\n",
    "# Flow\n",
    "# fan out\n",
    "builder.add_edge(START, \"search_wikipedia\")\n",
    "builder.add_edge(START, \"search_web\")\n",
    "# fan in\n",
    "builder.add_edge(\"search_wikipedia\", \"generate_answer\")\n",
    "builder.add_edge(\"search_web\", \"generate_answer\")\n",
    "# aggregation\n",
    "builder.add_edge(\"generate_answer\", END)\n",
    "graph = builder.compile()\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c370a154-97f0-4d20-8406-ec5161f8fa42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "EfvPvAdvQqHg"
   },
   "source": [
    "### Test Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed1c01ff-bb2b-41fe-933a-56d19e6464c3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fa544ca0-10af-491e-ad7a-477d004413eb",
    "outputId": "3c9e4791-092a-4240-b38f-e3dd62e1d946"
   },
   "outputs": [],
   "source": [
    "result = graph.invoke({\"question\": \"Tell me about Nvidia and its growth\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08459dd2-4862-43f6-bbfb-90622e747a17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MepAz8hNEY0",
    "outputId": "d59d5bd2-69cf-4d4b-ca56-599696a8fe41"
   },
   "outputs": [],
   "source": [
    "print(result['answer'].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cbac4597-b936-4294-9cdd-d6f52e228e66",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "1. Parallel_Steps_Execution_in_Agentic_Systems_in_LangGraph",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
