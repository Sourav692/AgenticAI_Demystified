{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5ff8aff7-57cf-48d0-807a-a5c05e796fd3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "a3e3ebc4-57af-4fe4-bdd3-36aff67bf276"
   },
   "source": [
    "# Build a Supervisor Multi-Agent System for Financial Research and Data Analysis with LangGraph\n",
    "\n",
    "In this project we will be building a Multi-Agent System following the Supervisor Architecture. The Supervisor Agent will supervised two sub-agents, 'Financial Researcher' and 'Coder'to help get useful financial data, analyze and visualize them using graphs.\n",
    "\n",
    "![](https://i.imgur.com/VnGr1n3.png)\n",
    "\n",
    "\n",
    "### Supervisor Multi-Agent System for Financial Research and Data Analysis\n",
    "\n",
    "This project focuses on building a **Supervisor Multi-Agent System for Financial Research and Data Analysis**. The system uses a supervisor agent design, where a **Supervisor Agent** delegates tasks to specialized sub-agents to efficiently handle complex financial queries and data analysis tasks. The workflow is as follows:\n",
    "\n",
    "1. **Supervisor Agent**:\n",
    "   - Analyzes the user's query to determine the required actions.\n",
    "   - Dynamically delegates tasks to one of the following sub-agents:\n",
    "     - **Financial Researcher Agent**: Responsible for retrieving financial data.\n",
    "     - **Coder & Visualization Agent**: Responsible for data processing and visualization.\n",
    "   - Maintains control over the process by monitoring the state and progress of both sub-agents, ensuring the query is fully resolved.\n",
    "\n",
    "2. **Financial Researcher Agent**:\n",
    "   - Uses **financial and web search tools** to gather relevant data and insights based on the user query.\n",
    "   - Returns the collected data to the Supervisor Agent for further processing.\n",
    "   - Example: Retrieves financial metrics such as ROE (Return on Equity) for companies like NVIDIA, Apple, Intel, Microsoft, and Amazon.\n",
    "\n",
    "3. **Coder & Visualization Agent**:\n",
    "   - Takes the data provided by the Financial Researcher Agent or directly delegated by the Supervisor Agent.\n",
    "   - Uses **programming tools**, in this case Python, to:\n",
    "     - Process the data.\n",
    "     - Generate visualizations like bar charts, line graphs, etc., to represent the results.\n",
    "   - Sends the generated output back to the Supervisor Agent.\n",
    "\n",
    "4. **Dynamic Task Coordination**:\n",
    "   - The Supervisor Agent coordinates between the sub-agents iteratively, based on the task's progress and the current state.\n",
    "   - Continuously evaluates whether additional data collection, computation, or visualization is needed.\n",
    "   - Ensures seamless integration between data retrieval and analysis tasks.\n",
    "\n",
    "5. **Final Response**:\n",
    "   - Once all tasks are completed, the Supervisor Agent compiles the outputs from the sub-agents into a cohesive final response.\n",
    "   - Example: Produces a bar chart displaying the ROE values for the selected companies, fulfilling the user's query.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "18e0f613-3326-44af-ad55-d62e375994c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9hEI3WL328vZ"
   },
   "source": [
    "## Install OpenAI, LangGraph and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32a67992-fc1d-444a-b114-504601d21e40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0d30b6f7-3bec-4d9f-af50-43dfdc81ae6c",
    "outputId": "7235b36e-b77e-4b87-a62a-993f77f2a8be"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.14\n",
    "!pip install langchain-openai==0.3.0\n",
    "!pip install langchain-community==0.3.14\n",
    "!pip install langgraph==0.2.64\n",
    "!pip install langchain-experimental==0.3.4\n",
    "!pip install yfinance==0.2.51"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bdf8846c-6d1f-463e-906e-60ff1b36d41e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pSE8EoRXyuxx"
   },
   "source": [
    "## Install OpenBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "67811a73-b7fb-4762-a00a-61a9581c05cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "xRXDUoYN-3Xl",
    "outputId": "909b73cd-fad2-4475-bbfb-aa38a190e1ba"
   },
   "outputs": [],
   "source": [
    "!pip install openbb[all]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32830023-1b53-4d2a-b900-fbd68cd09b15",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "280815d4-5cce-45b7-be6b-9e7f6f2539e4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "ba7ae3b6-58b4-4dbf-d43b-304b8940af79"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "701a5fb3-e330-40fd-ad31-b1fb026ed39e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "djj1pH6A04BX"
   },
   "source": [
    "## Enter OpenBB Key\n",
    "\n",
    "Get a free API key from [here](https://my.openbb.co/app/platform/pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "11043285-6e25-43e1-a850-f72054888d50",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q2sKDYgEqOaP",
    "outputId": "73fad05f-862b-47ff-bfc5-45debb917288"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENBB_PAT = getpass('Enter OpenBB Personal Access Token (PAT): ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c77e61f3-54bf-4228-a229-1e7470403c24",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe6c5899-2abf-4ab7-82d9-ded38a44ba2f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "bb6cd3fa-7276-47d3-a489-522fc6d1d846"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8184d00-d8be-4c6d-bafc-0abee67a47e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "258d7ae6-d2bd-4bb5-9b60-33759475cddb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eba0f27b-b8b4-4d2f-bfbc-ef95b8d9cc2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['RUFF_CACHE_DIR'] = '/tmp/ruff_cache'\n",
    "\n",
    "from openbb import obb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5c762ff-f60b-47fe-99d2-50596be102ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7149423c-b849-45b5-a74b-908d6bb0dc57",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4a3LQeClFoi",
    "outputId": "e5f8afe6-f97d-45cb-f854-35d5b6e1ba50"
   },
   "outputs": [],
   "source": [
    "from openbb import obb\n",
    "# takes 1 min to setup\n",
    "# obb.account.login(pat=OPENBB_PAT)\n",
    "obb.user.credentials.fmp_api_key = dbutils.secrets.get(scope=\"AgenticAI\", key=\"fmp_api_key\")\n",
    "obb.user.credentials.polygon_api_key = dbutils.secrets.get(scope=\"AgenticAI\", key=\"polygon_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40b4e37e-3591-4959-8eda-c7f5b4d19710",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "TW0QaP_RzG2h"
   },
   "source": [
    "## Create Financial Tools\n",
    "\n",
    "**Financial Analysis Tools**:\n",
    "   The system integrates multiple tools to get useful financial data and metrics:\n",
    "   - **SEARCH_WEB**: Fetches general stock market information from the web.\n",
    "   - **GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS**: Provides insights into key financial metrics such as P/E ratio, ROE, etc.\n",
    "   - **GET_STOCK_NEWS**: Extracts the latest news and updates related to stocks or markets.\n",
    "   - **GET_GENERAL_MARKET_DATA**: Fetches data on overall market trends and performance.\n",
    "   - **GET_STOCK_TICKER**: Validates and fetches stock ticker symbols based on user queries.\n",
    "   - **GET_STOCK_PRICE_METRICS**: Retrieves price trends, performance, and metrics for specific stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3758ce93-ec18-4465-a08f-127c5c5efdfb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Ue8xgu9WpuPi"
   },
   "outputs": [],
   "source": [
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "tavily_search = TavilySearchAPIWrapper()\n",
    "\n",
    "@tool\n",
    "def search_web(query: str, num_results=10) -> list:\n",
    "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
    "    results = tavily_search.raw_results(query=query,\n",
    "                                        max_results=num_results,\n",
    "                                        search_depth='advanced',\n",
    "                                        include_answer=False,\n",
    "                                        include_raw_content=True)\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def get_stock_ticker_symbol(stock_name: str) -> str:\n",
    "    \"\"\"Get the symbol, name and CIK for any publicly traded company\"\"\"\n",
    "    # Use OpenBB to search for stock ticker symbol and company details by name.\n",
    "    # The provider \"sec\" fetches data from the U.S. Securities and Exchange Commission (SEC).\n",
    "    res = obb.equity.search(stock_name, provider=\"sec\")\n",
    "\n",
    "    # Convert the result to a DataFrame and format it as markdown for readability.\n",
    "    stock_ticker_details = res.to_df().to_markdown()\n",
    "\n",
    "    # Prepare the output with the stock details.\n",
    "    output = \"\"\"Here are the details of the company and its stock ticker symbol:\\n\\n\"\"\" + stock_ticker_details\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_stock_price_metrics(stock_ticker: str) -> str:\n",
    "    \"\"\"Get historical stock price data, stock price quote and price performance data\n",
    "       like price changes for a specific stock ticker\"\"\"\n",
    "\n",
    "    # Fetch the latest stock price quote using \"cboe\" provider.\n",
    "    res = obb.equity.price.quote(stock_ticker, provider='cboe')\n",
    "    price_quote = res.to_df().to_markdown()\n",
    "\n",
    "    # Retrieve stock price performance metrics (e.g., percentage change) using \"finviz\" provider.\n",
    "    res = obb.equity.price.performance(symbol=stock_ticker, provider='finviz')\n",
    "    price_performance = res.to_df().to_markdown()\n",
    "\n",
    "    # Fetch historical price data for the past year using \"yfinance\" provider.\n",
    "    end_date = datetime.now()\n",
    "    start_date = (end_date - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "    res = obb.equity.price.historical(symbol=stock_ticker, start_date=start_date,\n",
    "                                      interval='1d', provider='yfinance')\n",
    "    price_historical = res.to_df().to_markdown()\n",
    "\n",
    "    # Combine the results into a formatted output.\n",
    "    output = (\"\"\"Here are the stock price metrics and data for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" +\n",
    "              \"Price Quote Metrics:\\n\\n\" + price_quote +\n",
    "              \"\\n\\nPrice Performance Metrics:\\n\\n\" + price_performance +\n",
    "              \"\\n\\nPrice Historical Data:\\n\\n\" + price_historical)\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_stock_fundamental_indicator_metrics(stock_ticker: str) -> str:\n",
    "    \"\"\"Get fundamental indicator metrics for a specific stock ticker\"\"\"\n",
    "\n",
    "    # Retrieve fundamental financial ratios (e.g., P/E ratio, ROE) using \"fmp\" provider.\n",
    "    res = obb.equity.fundamental.ratios(symbol=stock_ticker, period='annual',\n",
    "                                        limit=10, provider='fmp')\n",
    "    fundamental_ratios = res.to_df().to_markdown()\n",
    "\n",
    "    # Fetch additional fundamental metrics (e.g., EBITDA, revenue growth) using \"yfinance\" provider.\n",
    "    res = obb.equity.fundamental.metrics(symbol=stock_ticker, period='annual',\n",
    "                                        limit=10, provider='yfinance')\n",
    "    fundamental_metrics = res.to_df().to_markdown()\n",
    "\n",
    "    # Combine fundamental ratios and metrics into a single output.\n",
    "    output = (\"\"\"Here are the fundamental indicator metrics and data for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" +\n",
    "              \"Fundamental Ratios:\\n\\n\" + fundamental_ratios +\n",
    "              \"\\n\\nFundamental Metrics:\\n\\n\" + fundamental_metrics)\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_stock_news(stock_ticker: str) -> str:\n",
    "    \"\"\"Get news article headlines for a specific stock ticker\"\"\"\n",
    "\n",
    "    # Define the date range to fetch news (last 45 days).\n",
    "    end_date = datetime.now()\n",
    "    start_date = (end_date - timedelta(days=45)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Retrieve news headlines for the stock using \"tmx\" provider.\n",
    "    res = obb.news.company(symbol=stock_ticker, start_date=start_date, provider='tmx', limit=50)\n",
    "    news = res.to_df()\n",
    "\n",
    "    # Extract relevant columns (symbols and titles) and format as markdown.\n",
    "    news = news[['symbols', 'title']].to_markdown()\n",
    "\n",
    "    # Prepare the output with the news headlines.\n",
    "    output = (\"\"\"Here are the recent news headlines for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" + news)\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_general_market_data() -> str:\n",
    "    \"\"\"Get general data and indicators for the whole stock market including,\n",
    "       most actively traded stocks based on volume, top price gainers and top price losers.\n",
    "       Useful when you want an overview of the market and what stocks to look at.\"\"\"\n",
    "\n",
    "    # Retrieve the most actively traded stocks using \"yfinance\" provider.\n",
    "    res = obb.equity.discovery.active(sort='desc', provider='yfinance', limit=15)\n",
    "    most_active_stocks = res.to_df().to_markdown()\n",
    "\n",
    "    # Fetch the top price gainers using \"yfinance\" provider.\n",
    "    res = obb.equity.discovery.gainers(sort='desc', provider='yfinance', limit=15)\n",
    "    price_gainers = res.to_df().to_markdown()\n",
    "\n",
    "    # Retrieve the top price losers using \"yfinance\" provider.\n",
    "    res = obb.equity.discovery.losers(sort='desc', provider='yfinance', limit=15)\n",
    "    price_losers = res.to_df().to_markdown()\n",
    "\n",
    "    # Combine the market data into a single formatted output.\n",
    "    output = (\"\"\"Here's some detailed information of the stock market which includes most actively traded stocks, gainers and losers:\\n\\n\"\"\" +\n",
    "              \"Most actively traded stocks:\\n\\n\" + most_active_stocks +\n",
    "              \"\\n\\nTop price gainers:\\n\\n\" + price_gainers +\n",
    "              \"\\n\\nTop price losers:\\n\\n\" + price_losers)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd7a0b82-fbeb-409c-9719-1a94f3fd419c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ghP8Nm5EqVbp"
   },
   "source": [
    "## Create Coding Tools\n",
    "\n",
    "Create a tool to run python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7adc6c43-1e8a-411a-a469-35b9ec741789",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tdcOCmNzqZ_m"
   },
   "outputs": [],
   "source": [
    "from langchain_experimental.utilities import PythonREPL\n",
    "from langchain_core.tools import tool\n",
    "from typing import Annotated\n",
    "\n",
    "repl = PythonREPL()\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute code, generate charts.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n```python\\n{code}\\n```\\nCODE OUTPUT:\\n {result}\"\n",
    "    return result_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d65515d-870c-4ea0-93b6-bd0b6abefeec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "d32962d2-5487-496d-aefc-2a3b0d194985"
   },
   "source": [
    "### Create Agent Supervisor\n",
    "\n",
    "It will use LLM with structured output routing to choose the next worker node (sub-agent) OR finish processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "41d7eab8-e73d-4180-81b5-8b486d0553c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explanation: How the Supervisor Agent Works\n",
    "\n",
    "The notebook defines a **Supervisor Agent** that manages a workflow between two specialized sub-agents: a \"researcher\" (for financial data gathering) and a \"coder\" (for code execution and visualization).\n",
    "\n",
    "#### How the Supervisor Agent is Built and Used\n",
    "\n",
    "- **LLM Integration**: The agent uses OpenAI's GPT-4o model via `ChatOpenAI` to interpret user requests and decide which sub-agent should act next.\n",
    "- **Structured Output**: The LLM is prompted with a system message (`SUPERVISOR_AGENT_PROMPT`) that describes the roles of the \"researcher\" and \"coder\". It is instructed to analyze the conversation and select the next worker or finish the process.\n",
    "- **Router Schema**: The `Router` TypedDict defines the possible next steps: \"researcher\", \"coder\", or \"FINISH\".\n",
    "- **Supervisor Node Function**: The `supervisor_node` function takes the current conversation state, appends the system prompt, and invokes the LLM with structured output. Based on the LLM's response, it routes the workflow to the appropriate sub-agent or ends the process.\n",
    "- **State Management**: The agent maintains a list of messages and the current \"next\" worker in the state, ensuring context is preserved across steps.\n",
    "\n",
    "#### How the Agent Works\n",
    "\n",
    "1. **Receives User Request**: The user provides a request (e.g., \"Get the stock price details of Nvidia and Intel and display it as a line chart\").\n",
    "2. **Supervisor Decides**: The supervisor agent analyzes the request and conversation history, then decides whether the \"researcher\" or \"coder\" should act next.\n",
    "3. **Routes to Sub-Agent**: The chosen sub-agent performs its task (e.g., data gathering or code execution) and reports back.\n",
    "4. **Iterative Process**: The supervisor continues to route between sub-agents as needed, based on their outputs, until the task is complete.\n",
    "5. **Finish**: When the workflow is done, the supervisor returns \"FINISH\" to end the process.\n",
    "\n",
    "This design enables dynamic, multi-step workflows where each sub-agent specializes in a part of the task, and the supervisor coordinates the overall process using LLM-driven reasoning and structured output routing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2c00c26-b45f-4493-a466-db198767978d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explanation of the Supervisor Agent Code\n",
    "\n",
    "This code defines the logic for a \"Supervisor Agent\" that manages a workflow between two sub-agents: a \"researcher\" and a \"coder\".\n",
    "\n",
    "#### 1. Supervisor Prompt\n",
    "- `SUPERVISOR_AGENT_PROMPT` is a system prompt that instructs the LLM (Large Language Model) to act as a supervisor.\n",
    "- The supervisor's job is to decide, based on the conversation and user request, which worker (\"researcher\" or \"coder\") should act next.\n",
    "- The supervisor is told to analyze results after each worker acts and to finish the process by responding with \"FINISH\" when appropriate.\n",
    "\n",
    "#### 2. Router and State Schemas\n",
    "- `Router` is a TypedDict that restricts the supervisor's output to one of three options: \"researcher\", \"coder\", or \"FINISH\".\n",
    "- `State` is a TypedDict that keeps track of the conversation messages and the next worker to act.\n",
    "\n",
    "#### 3. LLM Initialization\n",
    "- `llm` is an instance of `ChatOpenAI` using the \"gpt-4o\" model with deterministic output (`temperature=0`).\n",
    "\n",
    "#### 4. Supervisor Node Function\n",
    "- `supervisor_node` is a function that:\n",
    "  - Prepares the message history by adding the supervisor prompt to the conversation.\n",
    "  - Calls the LLM with structured output, expecting a response that matches the `Router` schema.\n",
    "  - Determines the next worker to act (`goto`). If the response is \"FINISH\", it sets `goto` to `END` (a special marker).\n",
    "  - Returns a `Command` object that tells the workflow which worker to call next and updates the state accordingly.\n",
    "\n",
    "This setup enables dynamic, LLM-driven routing between specialized agents in a multi-step workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2e8a2f02-5bbf-4be6-91e4-838fceaacd13",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "df2bd80b-c477-4d74-8faa-1c0548622239"
   },
   "outputs": [],
   "source": [
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "from typing import Literal, Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "members = [\"researcher\", \"coder\"]\n",
    "\n",
    "SUPERVISOR_AGENT_PROMPT = f\"\"\"You are a supervisor tasked with managing a conversation between the following workers:\n",
    "                              {members}.\n",
    "\n",
    "                              Given the following user request, respond with the worker to act next.\n",
    "                              Each worker will perform a task and respond with their results and status.\n",
    "                              Analyze the results carefully and decide which worker to call next accordingly.\n",
    "                              Remember researcher agent can search for information and coder agent can code.\n",
    "                              When finished, respond with FINISH.\"\"\"\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    next: str\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "def supervisor_node(state: State) -> Command[Literal[\"researcher\", \"coder\", \"__end__\"]]:\n",
    "    messages = [{\"role\": \"system\", \"content\": SUPERVISOR_AGENT_PROMPT},] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "789d033e-b599-4e12-acff-3fddb83783fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "messages = [{\"role\": \"system\", \"content\": SUPERVISOR_AGENT_PROMPT},] + [(\"user\", \"Get the stock price details of nvidia and intel and display it as a line chart in the same plot comparing the trend\")]\n",
    "response = llm.with_structured_output(Router).invoke(messages)\n",
    "response[\"next\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "934d2b98-54e3-414d-b4c2-ed8451d51fb0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "a07d507f-34d1-4f1b-8dde-5e58d17b2166"
   },
   "source": [
    "## Construct Graph with Supervisor Agent and Worker Sub-Agents\n",
    "\n",
    "We're ready to start building the graph. Below, we define the sub-agents and connect them as nodes to the supervisor agent node\n",
    "\n",
    "We use the LangGraph built-in `create_react_agent(...)` function to build the two tool-based sub-agents easily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ad35380-99e3-4bac-b091-eb4aa68cab07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This code defines a financial researcher sub-agent and its node function for use in a LangGraph multi-agent workflow.\n",
    "\n",
    "- **Agent Creation**:  \n",
    "  `research_agent` is created using `create_react_agent`, with a set of financial data tools. The `state_modifier` prompt instructs the agent to only search and analyze data, not perform math or coding, and to report back to the supervisor when done.\n",
    "\n",
    "- **Node Function**:  \n",
    "  The `research_node` function runs the researcher agent with the current state, prints the last message from the agent for logging, and returns a `Command` to update the workflow state.\n",
    "\n",
    "- **Message Attribution**:  \n",
    "  The agent's output is wrapped in a `HumanMessage` with `name=\"researcher\"`. This ensures the message is clearly attributed to the researcher in the conversation history, even though it is generated by an agent. This labeling is important for the supervisor to track which agent produced each message and to maintain a consistent message schema throughout the workflow.\n",
    "\n",
    "This setup allows the supervisor agent to coordinate tasks between specialized agents, with clear attribution of each message to its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f2e324e-ac19-4493-9896-3ce4c6c2bb25",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6a430af7-8fce-4e66-ba9e-d940c1bc48e8"
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from langchain_core.messages import trim_messages\n",
    "\n",
    "# Create Financial Researcher Sub-Agent\n",
    "research_agent = create_react_agent(\n",
    "    llm, tools=[search_web,\n",
    "            get_stock_ticker_symbol,\n",
    "            get_stock_price_metrics,\n",
    "            get_stock_fundamental_indicator_metrics,\n",
    "            get_stock_news,\n",
    "            get_general_market_data], state_modifier=\"\"\"You are a financial researcher who excels in searching the web and financial platforms and analyzing the data.\n",
    "                                                        DO NOT do any math or coding.\n",
    "                                                        Once your task is done report back to the supervisor.\"\"\"\n",
    ")\n",
    "\n",
    "# create node function for financial researcher sub-agent\n",
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = research_agent.invoke(state)\n",
    "    print(f\"Message from researcher: {result['messages'][-1].content}\")\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f6fec451-c96b-4d8c-885a-1a525f4df6a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "This code defines a coder sub-agent and its node function for use in a LangGraph multi-agent workflow.\n",
    "\n",
    "- **Agent Creation**:  \n",
    "  `code_agent` is created using `create_react_agent`, with a Python REPL tool. The `state_modifier` prompt instructs the agent to write and run Python code, visualize charts, and only extract relevant data before coding or plotting. The agent is told to report back to the supervisor when done.\n",
    "\n",
    "- **Node Function**:  \n",
    "  The `code_node` function runs the coder agent with the current state, prints the last message from the agent for logging, and returns a `Command` to update the workflow state.\n",
    "\n",
    "- **Message Attribution**:  \n",
    "  The agent's output is wrapped in a `HumanMessage` with `name=\"coder\"`. This ensures the message is clearly attributed to the coder in the conversation history, even though it is generated by an agent. This labeling is important for the supervisor to track which agent produced each message and to maintain a consistent message schema throughout the workflow.\n",
    "\n",
    "This setup allows the supervisor agent to coordinate tasks between specialized agents, with clear attribution of each message to its source."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8b27d247-f1f7-4eb5-a89c-0da893beb0e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Create Coder Sub-Agent\n",
    "code_agent = create_react_agent(llm, tools=[python_repl_tool], state_modifier=\"\"\"You are a coder who can write and run python code and also visualize charts and graphs.\n",
    "                                                                                 Only extract the most relevant data related to the question before running code or creating graphs.\n",
    "                                                                                 Once your task is done report back to the supervisor.\"\"\")\n",
    "\n",
    "# create node function for coder sub-agent\n",
    "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    result = code_agent.invoke(state)\n",
    "    print(f\"Message from Coder Agent: {result['messages'][-1].content}\")\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27355c8f-cff5-4486-9eca-0835edfa1143",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# build the agent graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"researcher\", research_node)\n",
    "builder.add_node(\"coder\", code_node)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e95c05f9-196a-4e5b-bb91-209f55381368",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "id": "0175fe14-5854-4197-b7e8-559335d0f81b",
    "outputId": "55259285-0d14-4362-c380-f79409976a2c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ac5e217d-2576-46a4-a01a-90ec19f76a35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "d36496de-7121-4c49-8cb6-58c943c66628"
   },
   "source": [
    "## Invoke the Team and Test Agent\n",
    "\n",
    "With the graph created, we can now invoke it and see how it performs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c9999003-568d-48e0-8c68-c4b694f418b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NyQsL4WtLjIT"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "\n",
    "def call_multi_agent_system(agent, prompt):\n",
    "    events = agent.stream(\n",
    "        {\"messages\": [(\"user\", prompt)]},\n",
    "        {\"recursion_limit\": 150},\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "\n",
    "    for event in events:\n",
    "        # event[\"messages\"][-1]\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    display(Markdown(event[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f62419d-0448-438b-9068-5655518cd9ed",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "56ba78e9-d9c1-457c-a073-d606d5d3e013",
    "outputId": "b222dea5-b029-40c4-d994-320f86d4e2ef"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"Get the stock price details of nvidia and intel\n",
    "           and display it as a line chart in the same plot comparing the trend\"\"\"\n",
    "call_multi_agent_system(graph, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f9aa266-0788-432e-81f9-6841d9c2772a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Lgz1BWeUSGzM",
    "outputId": "3f8b7b05-69dd-497d-dd52-f9972980cb2b"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"find the top 10 companies with the largest market cap and plot it as a bar chart\"\"\"\n",
    "call_multi_agent_system(graph, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e95c1aef-b4aa-4a1a-9402-7dbaefed5cad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "gZ3lbelGFSbA",
    "outputId": "48239331-5484-4fe6-e74a-9d3539ac5e5f"
   },
   "outputs": [],
   "source": [
    "query = \"\"\"get the ROE values for nvidia, apple, intel, microsoft, amazon and plot it as a bar chart\"\"\"\n",
    "call_multi_agent_system(graph, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "db0f9f82-15b7-4210-ad39-289fddd59f90",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "E45KOoiZU81I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M8_Project_ Build_a_Supervisor_Multi_Agent_System_for_Financial_Research_and_Data_Analysis",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
