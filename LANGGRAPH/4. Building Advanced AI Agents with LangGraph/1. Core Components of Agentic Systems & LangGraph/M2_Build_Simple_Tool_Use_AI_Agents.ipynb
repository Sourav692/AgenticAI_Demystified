{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "515b618a-c313-401d-9402-93804602157a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
   },
   "source": [
    "# Build Simple Tool-Use AI Agents in LangGraph\n",
    "\n",
    "Here we will extend the capability of the previously built Augmented LLM with feedback from the tool execution back to the LLM node to process it and generate human-like answers to user queries.\n",
    "\n",
    "### Tool-based Agentic AI System\n",
    "\n",
    "- Dynamic Decision-Making: LLM determines whether to directly respond or invoke a tool based on the query context.\n",
    "- Seamless Tool Integration: External tools are integrated to handle specific tasks, such as real-time web queries or computations.\n",
    "- Workflow Flexibility: Conditional routing ensures efficient task delegation:\n",
    "  - Tool Required: Routes to tool execution.\n",
    "  - No Tool Required: Ends the workflow with an LLM response.\n",
    "- Feedback Loop: Incorporates a feedback loop to improve responses by combining LLM insights and tool outputs to further improve responses or call more tools if needed\n",
    "\n",
    "![](https://i.imgur.com/DHxiOLl.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04fe71a5-256e-4bcc-b31d-c5e3a5ebe04a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ff151ef1-fa30-482a-94da-8f49964afbc3"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.14\n",
    "!pip install langchain-openai==0.3.0\n",
    "!pip install langchain-community==0.3.14\n",
    "!pip install langgraph==0.2.64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5837f76a-28f7-42f8-ae91-e8465e184117",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "672e0cf8-fe44-4f03-bb09-3fa3fcec3d4b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "e9fc3c4f-ce4e-47cd-ba27-6b890da5af92"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b3587013-49ee-4ba0-a4e6-9cb5dccaf6d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4143b4c2-3153-4230-90c8-26ee9bb3a57b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "e62f3ede-fde8-4793-9c5c-4175b636504c"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "28c3b2b8-140b-4efe-9759-2e1a37e1ed35",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64d6009d-1f4f-4e73-94df-cd835c88b264",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "749c3310-4ec3-4e59-b28c-9445421adf87",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
   },
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.\n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "46011ea8-82f6-4cac-b43c-e6aa4d23bca4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "51ae22a0-fd55-466b-9ebe-277ca8c18802",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mMwPwbV-mNQm"
   },
   "source": [
    "## Augment the LLM with tools\n",
    "\n",
    "Here we define our custom search tool and then bind it to the LLM to augment the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "615188cc-1035-489c-af92-3bda68744aa1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2lYXBn1ImzlB"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "tavily_search = TavilySearchAPIWrapper()\n",
    "@tool\n",
    "def search_web(query: str, num_results=5):\n",
    "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
    "    results = tavily_search.raw_results(query=query,\n",
    "                                        max_results=num_results,\n",
    "                                        search_depth='advanced',\n",
    "                                        include_raw_content=True)\n",
    "    return results\n",
    "\n",
    "tools = [search_web]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5e262cc-b3e9-4d09-82e0-dad782b47bcf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjOYMS0rn1CF",
    "outputId": "672b4674-d154-4331-aad0-100075ccd7a9"
   },
   "outputs": [],
   "source": [
    "llm_with_tools.invoke('what is the latest news on nvidia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c9de8b9-6952-4494-8319-d66c5c269d0a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NPFD28OWjGQM"
   },
   "source": [
    "## Create the Graph with the Tool-Use Agentic System\n",
    "\n",
    "![](https://i.imgur.com/DHxiOLl.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fe80e52-a269-4bdf-ac31-ad0b574c3093",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IJvHs_Py3uCV"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Augmented LLM with Tools Node function\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    current_state = state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(current_state)]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "# Conditional Edge\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from LLM is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    [\"tools\", END]\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\") # this is the key feedback loop\n",
    "builder.add_edge(\"tools\", END)\n",
    "agent = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8601fa38-1e07-42a5-9d78-e20ac59bf77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "JR2L3D5Y3uH9",
    "outputId": "1b606d4e-4216-4cdb-ba2a-4581df847527"
   },
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50e2a182-a515-4bd3-a6b6-2c0a52106cdf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
    "outputId": "91524848-d16b-439b-953d-5396a196d083"
   },
   "outputs": [],
   "source": [
    "user_input = \"Explain AI in 2 bullets\"\n",
    "for event in agent.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5888adba-4604-432b-bbd9-26819d14b57e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zYQrB6383i",
    "outputId": "29828380-44a6-48ea-824a-87fde936bf18"
   },
   "outputs": [],
   "source": [
    "user_input = \"What is the latest news on OpenAI product releases\"\n",
    "for event in agent.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7e344451-b9ff-4019-a44e-55ff96013b7f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICTlpMAqnL8L",
    "outputId": "07dbb9e8-5f69-4f5e-dc51-ee5e19c91ac3"
   },
   "outputs": [],
   "source": [
    "event['messages'][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "08173da9-d548-4226-b7a5-2ffda52ee77f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 324
    },
    "id": "T4h42-u94Jmb",
    "outputId": "6e2b715e-849d-47fd-c639-eafcdcae93b4"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(event['messages'][-1].content))"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "M2_Build_Simple_Tool_Use_AI_Agents",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
