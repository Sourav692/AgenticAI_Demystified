{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1dddff5c-69f6-48ce-a544-8bdaed41cc98",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
   },
   "source": [
    "# Build an Augmented LLM with Tools in LangGraph\n",
    "\n",
    "We already know Tools help the LLM interact with external sources of information like web search\n",
    "\n",
    "Augmented LLM with Search Tool: Here we will build a simple augmented LLM using the capabilities of Tavily Search as a tool to allow the LLM to fetch relevant information from the web when necessary.\n",
    "\n",
    "![](https://i.imgur.com/5r015dw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5ddd7be-f93b-418b-99bd-ee5b6122fe7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff151ef1-fa30-482a-94da-8f49964afbc3",
    "outputId": "52cdc736-fa18-4333-8943-571bb2f47728"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.14\n",
    "!pip install langchain-openai==0.3.2\n",
    "!pip install langchain-community==0.3.14\n",
    "!pip install langgraph==0.2.66"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9020f9be-0506-4daa-a690-daf35b730927",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2cc7d842-3ac7-4710-9d84-96a3383a4605",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "03b64bdf-0417-453e-da30-9040cba4655e"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "06447ec0-0d41-4f9e-a878-8e9dab0041cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "295fe543-0824-444a-b2c6-2d259e96f835",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "6eba8ef8-3bc5-4762-f47f-e984ea0c496b"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7547ec77-0682-45ce-a049-dcf699db18dc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2e68a803-5570-4ad8-8e8a-6fcac208c60b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1fe477a6-1a84-4d7a-938e-940101ec61b1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
   },
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.\n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3a35a5c-d5e2-412d-adbc-9b7b82548460",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d1878f87-cd83-406d-b63d-acf1f3fd4e2e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "888509e1-cbde-4c03-99a0-2560dd2e262d"
   },
   "source": [
    "## Augment the LLM with tools\n",
    "\n",
    "Here we define our custom search tool and then bind it to the LLM to augment the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "25eccd53-2044-4eb5-b58e-5c56bc866690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2lYXBn1ImzlB"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "tavily_search = TavilySearchAPIWrapper()\n",
    "@tool\n",
    "def search_web(query: str, num_results=5):\n",
    "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
    "    results = tavily_search.raw_results(query=query,\n",
    "                                        max_results=num_results,\n",
    "                                        search_depth='advanced',\n",
    "                                        include_raw_content=True)\n",
    "    return results\n",
    "\n",
    "tools = [search_web]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e3180e82-5c64-4020-aed7-b3fb4a945a42",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "52btTC1XjAC3",
    "outputId": "d18871ad-42d0-4508-e194-73d081bddd36"
   },
   "outputs": [],
   "source": [
    "llm_with_tools.invoke('what is AI in 1 line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6a06588e-15ad-432d-8926-a3461351f0e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wjOYMS0rn1CF",
    "outputId": "8fe3b02b-148c-4ea7-c83f-eb9a8b8f6229"
   },
   "outputs": [],
   "source": [
    "llm_with_tools.invoke('what is the latest news on nvidia')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3539a1be-4a6c-4702-9622-1ba412991e30",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NPFD28OWjGQM"
   },
   "source": [
    "## Create the Graph with the Augmented LLM\n",
    "\n",
    "![](https://i.imgur.com/5r015dw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6679d083-a9b1-4c47-b607-21b2dc4ea28a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IJvHs_Py3uCV"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "# Augmented LLM with Tools Node function\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    current_state = state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(current_state)]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "# Conditional Edge\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from LLM is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    [\"tools\", END]\n",
    ")\n",
    "builder.add_edge(\"tools\", END)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "439b25ec-93ca-446c-8c31-35b0df427109",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "JR2L3D5Y3uH9",
    "outputId": "f4b09c6f-e2f8-471f-9b2b-5d1ed8b52500"
   },
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "503b5a33-c01d-4f3f-8973-186ee1f56afa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
    "outputId": "71b24894-aa5e-492f-c4bf-e007d776ac3d"
   },
   "outputs": [],
   "source": [
    "user_input = \"Explain AI in 2 bullets\"\n",
    "for event in graph.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dd210679-3d92-4e49-b222-bd4e77c59cfe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zYQrB6383i",
    "outputId": "5a4d52db-9562-45ce-a68b-cb567a7d85e9"
   },
   "outputs": [],
   "source": [
    "user_input = \"What is the latest news on OpenAI product releases\"\n",
    "for event in graph.stream({\"messages\": user_input},\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {},
   "notebookName": "M2_Augmented_LLM_with_Tools",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
