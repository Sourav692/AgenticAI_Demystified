{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04bd62c9-4f3d-438c-8a28-6fba71c6e984",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NffLMDtsJFsY"
   },
   "source": [
    "# Build a Customer Support Router Agentic RAG System\n",
    "\n",
    "In this project, we will leverage the power of AI Agents and RAG Systems to build an intelligent Router Agentic RAG System to handle customer support queries using a custom knowledgebase.\n",
    "\n",
    "![](https://i.imgur.com/bLCdxCI.png)\n",
    "\n",
    "### Intelligent Router Agentic RAG System\n",
    "\n",
    "This project focuses on building an **Intelligent Router Agentic RAG System** that combines intelligent query analysis, sentiment detection, and dynamic routing with Retrieval-Augmented Generation (RAG) to handle diverse user inquiries efficiently. The workflow includes the following components:\n",
    "\n",
    "1. **Query Categorization and Sentiment Analysis**:\n",
    "   - The system uses **OpenAI GPT-4o** to analyze the user's query and determine:\n",
    "     - **Query Category**: Identifies the type of problem, such as billing, technical issues, or general queries.\n",
    "     - **User Sentiment**: Evaluates the user's sentiment (positive, neutral, or negative) to determine if escalation is needed.\n",
    "\n",
    "2. **Intelligent Routing**:\n",
    "   - Based on the **query_category** and **query_sentiment**, the system routes the query to the appropriate handling node:\n",
    "     - **Escalate to Human**: If the sentiment is negative, the query is escalated to a human for resolution.\n",
    "     - **Generate Billing Response**: Queries related to billing are routed to generate an appropriate response.\n",
    "     - **Generate Technical Response**: Technical queries are routed for a specialized technical response.\n",
    "     - **Generate General Response**: General queries are handled with context-aware responses.\n",
    "\n",
    "3. **Knowledge Base Integration (RAG)**:\n",
    "   - The system integrates with a **Knowledge Base (Vector Database)** to augment responses with relevant and accurate information.\n",
    "   - Retrieval-Augmented Generation (RAG) ensures that responses are grounded in the latest and most reliable data.\n",
    "\n",
    "4. **Escalation Mechanism**:\n",
    "   - Negative sentiment triggers an **escalation to a human**, ensuring the user receives empathetic and personalized support for critical issues.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "acd7f264-e3f9-49a0-a95d-9a9fea12bd4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "9hEI3WL328vZ"
   },
   "source": [
    "## Install OpenAI, LangGraph and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2f4ae8b-26d5-460d-b253-5ce3b960ca47",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dzjE7G_8KOUM"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain==0.3.14\n",
    "!pip install -q langchain-openai==0.3.0\n",
    "!pip install -q langchain-community==0.3.14\n",
    "!pip install -q langgraph==0.2.64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50f8bc80-d94b-4b07-9a0f-5fb1cf6ae43c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "f64P4sY6RtNA"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain-chroma==0.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c6074cef-43a4-4c5a-b3e0-d3d613776535",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1e243b2-48d6-4ee1-8655-ad8d42da787b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8a4da614-ed2b-4d74-838f-bfe0ab4fd51f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "cv3JzCEx_PAd"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8dd8d91d-991d-4796-a155-124c397ff854",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20f4215c-01b2-4ba2-939f-e6f2251eb71a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6ecba799-b5ea-430a-bb0b-ed27e3911f43",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "iLVgrOIgR_Z1"
   },
   "source": [
    "## Load Company Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fcbbaa98-429f-44aa-84d9-2f5696af0b9d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Mjlzx9bxR-1C",
    "outputId": "be597db9-f7f3-4f08-c5d0-0d2715949e7b"
   },
   "outputs": [],
   "source": [
    "# # or download manually from https://drive.google.com/file/d/1CWHutosAcJ6fiddQW5ogvg7NgLstZJ9j/view?usp=sharing and upload to colab or your notebook location\n",
    "# !gdown 1CWHutosAcJ6fiddQW5ogvg7NgLstZJ9j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "22ee891b-870b-4c5b-b910-a9359bf3cc37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7NzAAMXyTSAH",
    "outputId": "77ca97b8-369c-43cc-97a3-dcb280e6dec3"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"./docs/router_agent_documents.json\", \"r\") as f:\n",
    "    knowledge_base = json.load(f)\n",
    "\n",
    "knowledge_base[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8280beed-03e1-4ed5-89dd-174d82ed2edb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wi8ULKpHEc0Z",
    "outputId": "232e9f97-108a-4e4a-e626-8420797434a8"
   },
   "outputs": [],
   "source": [
    "knowledge_base[-3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cdf285b-8cff-4df5-a153-040f4ca293c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ne7fLkRTdiN",
    "outputId": "4157dad9-ef97-4d5d-849b-a156a64485a7"
   },
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "from tqdm import tqdm\n",
    "\n",
    "processed_docs = []\n",
    "\n",
    "for doc in tqdm(knowledge_base):\n",
    "    metadata = doc['metadata']\n",
    "    data = doc['text']\n",
    "    processed_docs.append(Document(page_content=data,\n",
    "                                   metadata=metadata))\n",
    "\n",
    "processed_docs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a9468bcc-2c6c-41fb-a106-6ade8260c0ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "M-NDea2_HAZ-"
   },
   "source": [
    "## Create Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd279d12-e2ec-4dac-a7a0-9dc932085302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "371ec046-c63f-4219-9a2f-03a6f46c23ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "f3Ngz9vqUGt3"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "# details here: https://openai.com/blog/new-embedding-models-and-api-updates\n",
    "openai_embed_model = OpenAIEmbeddings(model='text-embedding-3-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c25e8e05-1253-48f3-83c4-c82a01974c83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "g6C6d4AkUVhs"
   },
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "kbase_db = Chroma.from_documents(documents=processed_docs,\n",
    "                                  collection_name='knowledge_base',\n",
    "                                  embedding=openai_embed_model,\n",
    "                                  # need to set the distance function to cosine else it uses euclidean by default\n",
    "                                  # check https://docs.trychroma.com/guides#changing-the-distance-function\n",
    "                                  collection_metadata={\"hnsw:space\": \"cosine\"},\n",
    "                                  persist_directory=\"./knowledge_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbcb6ff2-f016-417f-bf92-26529e177e06",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "-Wppf1mhUw0V"
   },
   "outputs": [],
   "source": [
    "kbase_search = kbase_db.as_retriever(search_type=\"similarity_score_threshold\",\n",
    "                                     search_kwargs={\"k\": 3, \"score_threshold\": 0.2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "20bbcdd2-747e-4d35-8f18-f19bfe3792a6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryudORhuUNDb",
    "outputId": "318b8b61-4f18-48f4-8fd9-f7b77b99e824"
   },
   "outputs": [],
   "source": [
    "query = 'what is your refund policy?'\n",
    "metadata_filter = {'category' : 'general'}\n",
    "# Update retriever search_kwargs dynamically\n",
    "kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
    "kbase_search.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "da05c0a5-fbe5-426a-9a7c-1958feb927ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gz6MvJyTeWQD",
    "outputId": "7181f0e3-a4a0-4cd9-e3ef-7d58d1b5aceb"
   },
   "outputs": [],
   "source": [
    "query = 'what is your refund policy'\n",
    "metadata_filter = {'category' : 'General'}\n",
    "# Update retriever search_kwargs dynamically\n",
    "kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
    "kbase_search.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "61581dd4-4057-4e78-99dc-13f2c80d4095",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FeCqpNFmXGRo",
    "outputId": "c264e81d-ae66-45d7-e058-cfa1af0691af"
   },
   "outputs": [],
   "source": [
    "query = 'what is your refund policy'\n",
    "metadata_filter = {'category' : 'technical'}\n",
    "# Update retriever search_kwargs dynamically\n",
    "kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
    "kbase_search.invoke(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4fed97c2-cebf-4876-8753-66cc4e26ed2b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "4Um1WrTcJFsl"
   },
   "source": [
    "## Define the Customer Inquiry State\n",
    "\n",
    "We create a `CustomerSupportState` typed dictionary to keep track of each interaction:\n",
    "- **customer_query**: The text of the customer's question\n",
    "- **query_category**: Technical, Billing, or General (used for routing)\n",
    "- **query_sentiment**: Positive, Neutral, or Negative (used for routing)\n",
    "- **final_response**: The system's response to the customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7860f8b7-0c12-4540-99d9-e23b627c6a8b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "N2oH7LzqJFsn"
   },
   "outputs": [],
   "source": [
    "from typing import TypedDict, Literal\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class CustomerSupportState(TypedDict):\n",
    "    \"\"\"\n",
    "    customer_query: the original query from the customer.\n",
    "    query_category: the topic of the query (e.g., Technical, Billing).\n",
    "    query_sentiment: the emotional tone (e.g., Positive, Negative).\n",
    "    final_response: the system-generated response.\n",
    "    \"\"\"\n",
    "    customer_query: str\n",
    "    query_category: str\n",
    "    query_sentiment: str\n",
    "    final_response: str\n",
    "\n",
    "class QueryCategory(BaseModel):\n",
    "    categorized_topic: Literal['Technical', 'Billing', 'General']\n",
    "\n",
    "class QuerySentiment(BaseModel):\n",
    "    sentiment: Literal['Positive', 'Neutral', 'Negative']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ae7c2854-f316-4dd9-a00b-37c67d1606c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Explain TypeDict, Literal and BaseModel\n",
    "* TypedDict: Allows you to define a dictionary with a specific schema (i.e., typed keys and values). This is a lightweight structure * used for state management in memory (not validated like Pydantic models).\n",
    "* Literal: Restricts a value to a fixed set of string options.\n",
    "* BaseModel from pydantic: Used for data validation and parsing using Python type hints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e659958f-b64c-4fc3-93e3-faf96c0202e5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "QueryCategory(categorized_topic='Billing')  # ✅ Valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6e52905-05c6-4e8b-b2f5-45446965141c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# QueryCategory(categorized_topic='billing')    # ❌ Validation error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "03a930b8-036d-4e5d-a5cf-6fb7402e0ecb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "dL-RUuX-JFso"
   },
   "source": [
    "## Create Node Functions\n",
    "\n",
    "Each function below represents a stage in processing a customer inquiry:\n",
    "\n",
    "1. **categorize_inquiry**: Classifies the query into Technical, Billing, or General.\n",
    "2. **analyze_inquiry_sentiment**: Determines if the sentiment is Positive, Neutral, or Negative.\n",
    "3. **generate_technical_response**: Produces a response for technical issues.\n",
    "4. **generate_billing_response**: Produces a response for billing questions.\n",
    "5. **generate_general_response**: Produces a response for general queries.\n",
    "6. **escalate_to_human_agent**: Escalates the query to a human if sentiment is negative.\n",
    "7. **determine_route**: Routes the inquiry to the appropriate response node based on category and sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d98f002-ca00-4e44-99a9-e0d2421e281b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "XqvrHu8ZX2tn"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8cfe1c04-1232-44ab-b425-d4678f3db828",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IktZ07zDJFsp"
   },
   "outputs": [],
   "source": [
    "def categorize_inquiry(support_state: CustomerSupportState) -> CustomerSupportState:\n",
    "    \"\"\"\n",
    "    Classify the customer query into Technical, Billing, or General.\n",
    "    \"\"\"\n",
    "\n",
    "    query = support_state[\"customer_query\"]\n",
    "    ROUTE_CATEGORY_PROMPT = \"\"\"Act as a customer support agent trying to best categorize the customer query.\n",
    "                               You are an agent for an AI products and hardware company.\n",
    "\n",
    "                               Please read the customer query below and\n",
    "                               determine the best category from the following list:\n",
    "\n",
    "                               'Technical', 'Billing', or 'General'.\n",
    "\n",
    "                               Remember:\n",
    "                                - Technical queries will focus more on technical aspects like AI models, hardware, software related queries etc.\n",
    "                                - General queries will focus more on general aspects like contacting support, finding things, policies etc.\n",
    "                                - Billing queries will focus more on payment and purchase related aspects\n",
    "\n",
    "                                Return just the category name (from one of the above)\n",
    "\n",
    "                                Query:\n",
    "                                {customer_query}\n",
    "                            \"\"\"\n",
    "    prompt = ROUTE_CATEGORY_PROMPT.format(customer_query=query)\n",
    "    route_category = llm.with_structured_output(QueryCategory).invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        \"query_category\": route_category.categorized_topic\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3125a26a-bfcb-4a95-a251-0eace19e1fa7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uh2L4b4YaBVp",
    "outputId": "bbb9e7c1-8f43-4817-cf17-bd1ae369fa8b"
   },
   "outputs": [],
   "source": [
    "categorize_inquiry({\"customer_query\": \"Do you provide pretrained models?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "00edd36f-ed5b-4fd3-b265-0adbe7c710d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3CDsIqGbnNV",
    "outputId": "69551d83-ef86-4c68-9913-089390e84396"
   },
   "outputs": [],
   "source": [
    "categorize_inquiry({\"customer_query\": \"what is your refund policy?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c32569c4-780e-4c70-ad90-be6328fd56ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pa3vyedQbxin",
    "outputId": "9c4c39cf-66b6-4f28-a38a-04dfbaca688d"
   },
   "outputs": [],
   "source": [
    "categorize_inquiry({\"customer_query\": \"what payment methods are accepted?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "94630130-7581-4545-99ae-97c3d383590f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8xoHBg4HZ-tV"
   },
   "outputs": [],
   "source": [
    "def analyze_inquiry_sentiment(support_state: CustomerSupportState) -> CustomerSupportState:\n",
    "    \"\"\"\n",
    "    Analyze the sentiment of the customer query as Positive, Neutral, or Negative.\n",
    "    \"\"\"\n",
    "\n",
    "    query = support_state[\"customer_query\"]\n",
    "    SENTIMENT_CATEGORY_PROMPT = \"\"\"Act as a customer support agent trying to best categorize the customer query's sentiment.\n",
    "                                   You are an agent for an AI products and hardware company.\n",
    "\n",
    "                                   Please read the customer query below,\n",
    "                                   analyze its sentiment which should be one from the following list:\n",
    "\n",
    "                                   'Positive', 'Neutral', or 'Negative'.\n",
    "\n",
    "                                   Return just the sentiment (from one of the above)\n",
    "\n",
    "                                   Query:\n",
    "                                   {customer_query}\n",
    "                                \"\"\"\n",
    "    prompt = SENTIMENT_CATEGORY_PROMPT.format(customer_query=query)\n",
    "    sentiment_category = llm.with_structured_output(QuerySentiment).invoke(prompt)\n",
    "\n",
    "    return {\n",
    "        \"query_sentiment\": sentiment_category.sentiment\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82181777-0cf7-477e-8d13-c0a7dcf0ce3d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ByyxDpxd3Ht",
    "outputId": "6263a8dd-d6da-4ad0-ab8b-1b885d3d1a0c"
   },
   "outputs": [],
   "source": [
    "analyze_inquiry_sentiment({\"customer_query\": \"what is your refund policy?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7e310563-568b-45c1-a731-6f708a6a9544",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V2Q9rU7md6mm",
    "outputId": "5982749d-2612-459a-bb30-55f5a251db91"
   },
   "outputs": [],
   "source": [
    "analyze_inquiry_sentiment({\"customer_query\": \"what is your refund policy? I am really fed up with this product and need to refund it\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a08fea4-5b1f-44ee-addd-6f0408e02035",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "rgss3fymfknr"
   },
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from typing import Dict\n",
    "\n",
    "def generate_technical_response(support_state: CustomerSupportState) -> CustomerSupportState:\n",
    "    \"\"\"\n",
    "    Provide a technical support response by combining knowledge from the vector store and LLM.\n",
    "    \"\"\"\n",
    "    # Retrieve category and ensure it is lowercase for metadata filtering\n",
    "\n",
    "    categorized_topic = support_state[\"query_category\"]\n",
    "    query = support_state[\"customer_query\"]\n",
    "\n",
    "    # Use metadata filter for 'technical' queries\n",
    "    if categorized_topic.lower() == \"technical\":\n",
    "        metadata_filter = {\"category\": \"technical\"}\n",
    "        kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
    "\n",
    "        # Perform retrieval from VectorDB\n",
    "        relevant_docs = kbase_search.invoke(query)\n",
    "        retrieved_content = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "        # Combine retrieved information into the prompt\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            Craft a clear and detailed technical support response for the following customer query.\n",
    "            Use the provided knowledge base information to enrich your response.\n",
    "            In case there is no knowledge base information or you do not know the answer just say:\n",
    "\n",
    "            Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\n",
    "\n",
    "            Customer Query:\n",
    "            {customer_query}\n",
    "\n",
    "            Relevant Knowledge Base Information:\n",
    "            {retrieved_content}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Generate the final response using the LLM\n",
    "        chain = prompt | llm\n",
    "        tech_reply = chain.invoke({\n",
    "            \"customer_query\": query,\n",
    "            \"retrieved_content\": retrieved_content\n",
    "        }).content\n",
    "    else:\n",
    "        # For non-technical queries, provide a default response or a general handling\n",
    "        tech_reply = \"Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\"\n",
    "\n",
    "    # Update and return the modified support state\n",
    "    return {\n",
    "        \"final_response\": tech_reply\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2b9918a3-7654-40eb-85e3-0e2345569471",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AVXPLD2Zgf-z",
    "outputId": "8a7f0ea6-ae21-4eef-e73d-511556c946d3"
   },
   "outputs": [],
   "source": [
    "generate_technical_response({\"customer_query\": \"what is your refund policy?\", \"query_category\": \"General\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a406c4cc-313b-492a-b4f8-fc6bdfef0e63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RfrobVESgoA5",
    "outputId": "3aea83f9-e9b7-4253-ba46-e214c26f4439"
   },
   "outputs": [],
   "source": [
    "generate_technical_response({\"customer_query\": \"do you support on-prem models?\", \"query_category\": \"Technical\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7ed9a908-d346-43c4-81a3-3de22d46b218",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Ex9O4DW7iR7S"
   },
   "outputs": [],
   "source": [
    "def generate_billing_response(support_state: CustomerSupportState) -> CustomerSupportState:\n",
    "    \"\"\"\n",
    "    Provide a billing support response by combining knowledge from the vector store and LLM.\n",
    "    \"\"\"\n",
    "    # Retrieve category and ensure it is lowercase for metadata filtering\n",
    "    categorized_topic = support_state[\"query_category\"]\n",
    "    query = support_state[\"customer_query\"]\n",
    "\n",
    "    # Use metadata filter for 'billing' queries\n",
    "    if categorized_topic.lower() == \"billing\":\n",
    "        metadata_filter = {\"category\": \"billing\"}\n",
    "        kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
    "\n",
    "        # Perform retrieval from VectorDB\n",
    "        relevant_docs = kbase_search.invoke(query)\n",
    "        retrieved_content = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "        # Combine retrieved information into the prompt\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            Craft a clear and detailed billing support response for the following customer query.\n",
    "            Use the provided knowledge base information to enrich your response.\n",
    "            In case there is no knowledge base information or you do not know the answer just say:\n",
    "\n",
    "            Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\n",
    "\n",
    "            Customer Query:\n",
    "            {customer_query}\n",
    "\n",
    "            Relevant Knowledge Base Information:\n",
    "            {retrieved_content}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Generate the final response using the LLM\n",
    "        chain = prompt | llm\n",
    "        billing_reply = chain.invoke({\n",
    "            \"customer_query\": query,\n",
    "            \"retrieved_content\": retrieved_content\n",
    "        }).content\n",
    "    else:\n",
    "        # For non-billing queries, provide a default response or a general handling\n",
    "        billing_reply = \"Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\"\n",
    "\n",
    "    # Update and return the modified support state\n",
    "    return {\n",
    "        \"final_response\": billing_reply\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "24a6c7a9-8b16-48c6-ba38-fed826cc916f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "px5LnEH-iyRQ",
    "outputId": "4cb6b664-a1f4-4f88-c443-da6f06f2704b"
   },
   "outputs": [],
   "source": [
    "generate_billing_response({\"customer_query\": \"what payment methods are supported?\", \"query_category\": \"Billing\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79f6907c-3f5c-43fd-b954-0d12a41d18d5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "xTS_38PGjiKt"
   },
   "outputs": [],
   "source": [
    "def generate_general_response(support_state: CustomerSupportState) -> CustomerSupportState:\n",
    "    \"\"\"\n",
    "    Provide a general support response by combining knowledge from the vector store and LLM.\n",
    "    \"\"\"\n",
    "    # Retrieve category and ensure it is lowercase for metadata filtering\n",
    "    categorized_topic = support_state[\"query_category\"]\n",
    "    query = support_state[\"customer_query\"]\n",
    "\n",
    "    # Use metadata filter for 'general' queries\n",
    "    if categorized_topic.lower() == \"general\":\n",
    "        metadata_filter = {\"category\": \"general\"}\n",
    "        kbase_search.search_kwargs[\"filter\"] = metadata_filter\n",
    "\n",
    "        # Perform retrieval from VectorDB\n",
    "        relevant_docs = kbase_search.invoke(query)\n",
    "        retrieved_content = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "\n",
    "        # Combine retrieved information into the prompt\n",
    "        prompt = ChatPromptTemplate.from_template(\n",
    "            \"\"\"\n",
    "            Craft a clear and detailed general support response for the following customer query.\n",
    "            Use the provided knowledge base information to enrich your response.\n",
    "            In case there is no knowledge base information or you do not know the answer just say:\n",
    "\n",
    "            Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\n",
    "\n",
    "            Customer Query:\n",
    "            {customer_query}\n",
    "\n",
    "            Relevant Knowledge Base Information:\n",
    "            {retrieved_content}\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        # Generate the final response using the LLM\n",
    "        chain = prompt | llm\n",
    "        general_reply = chain.invoke({\n",
    "            \"customer_query\": query,\n",
    "            \"retrieved_content\": retrieved_content\n",
    "        }).content\n",
    "    else:\n",
    "        # For non-general queries, provide a default response or a general handling\n",
    "        general_reply = \"Apologies I was not able to answer your question, please reach out to +1-xxx-xxxx\"\n",
    "\n",
    "    # Update and return the modified support state\n",
    "    return {\n",
    "        \"final_response\": general_reply\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bea8b07c-64d5-474c-a54b-f62cabc25e8c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6Gw2y1tqjrMS",
    "outputId": "148adb95-46e0-49e7-cbd8-c6e36f56ea46"
   },
   "outputs": [],
   "source": [
    "generate_general_response({\"customer_query\": \"what is your refund policy?\", \"query_category\": \"General\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f934feca-05c7-4089-81f4-dfda744f1c61",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "udRwW-sscAwl"
   },
   "outputs": [],
   "source": [
    "def escalate_to_human_agent(support_state: CustomerSupportState) -> CustomerSupportState:\n",
    "    \"\"\"\n",
    "    Escalate the query to a human agent if sentiment is negative.\n",
    "    \"\"\"\n",
    "\n",
    "    return {\n",
    "        \"final_response\": \"Apologies, we are really sorry! Someone from our team will be reaching out to your shortly!\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "796dbd86-fdaf-40e8-8b3d-398ceaa7f28b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Ti3TUUiSkTHG"
   },
   "outputs": [],
   "source": [
    "def determine_route(support_state: CustomerSupportState) -> str:\n",
    "    \"\"\"\n",
    "    Route the inquiry based on sentiment and category.\n",
    "    \"\"\"\n",
    "    if support_state[\"query_sentiment\"] == \"Negative\":\n",
    "        return \"escalate_to_human_agent\"\n",
    "    elif support_state[\"query_category\"] == \"Technical\":\n",
    "        return \"generate_technical_response\"\n",
    "    elif support_state[\"query_category\"] == \"Billing\":\n",
    "        return \"generate_billing_response\"\n",
    "    else:\n",
    "        return \"generate_general_response\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b3d8db9-7f3a-47a1-8eb3-e18a0c046f3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "QahrWKv3JFsq"
   },
   "source": [
    "## Build and Compile the Workflow\n",
    "\n",
    "We construct a LangGraph workflow with the nodes defined above:\n",
    "1. **categorize_inquiry** → **analyze_inquiry_sentiment** → **route** to the proper response node.\n",
    "2. If negative, escalate to a human agent.\n",
    "3. Otherwise, produce an appropriate response (technical, billing, or general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae06a5b0-cdc4-4d9f-a134-ddccf32fabc9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "YmMiVOgqJFsr"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "# Create the graph with our typed state\n",
    "customer_support_graph = StateGraph(CustomerSupportState)\n",
    "\n",
    "# Add nodes for each function\n",
    "customer_support_graph.add_node(\"categorize_inquiry\", categorize_inquiry)\n",
    "customer_support_graph.add_node(\"analyze_inquiry_sentiment\", analyze_inquiry_sentiment)\n",
    "customer_support_graph.add_node(\"generate_technical_response\", generate_technical_response)\n",
    "customer_support_graph.add_node(\"generate_billing_response\", generate_billing_response)\n",
    "customer_support_graph.add_node(\"generate_general_response\", generate_general_response)\n",
    "customer_support_graph.add_node(\"escalate_to_human_agent\", escalate_to_human_agent)\n",
    "\n",
    "# Add edges to represent the processing flow\n",
    "customer_support_graph.add_edge(\"categorize_inquiry\", \"analyze_inquiry_sentiment\")\n",
    "customer_support_graph.add_conditional_edges(\n",
    "    \"analyze_inquiry_sentiment\",\n",
    "    determine_route,\n",
    "    [\n",
    "        \"generate_technical_response\",\n",
    "        \"generate_billing_response\",\n",
    "        \"generate_general_response\",\n",
    "        \"escalate_to_human_agent\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# All terminal nodes lead to the END\n",
    "customer_support_graph.add_edge(\"generate_technical_response\", END)\n",
    "customer_support_graph.add_edge(\"generate_billing_response\", END)\n",
    "customer_support_graph.add_edge(\"generate_general_response\", END)\n",
    "customer_support_graph.add_edge(\"escalate_to_human_agent\", END)\n",
    "\n",
    "# Set the entry point for the workflow\n",
    "customer_support_graph.set_entry_point(\"categorize_inquiry\")\n",
    "\n",
    "# Compile the graph into a runnable agent\n",
    "memory = MemorySaver()\n",
    "compiled_support_agent = customer_support_graph.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f2595ec7-f91a-4a33-8a6a-1586028bf28d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "Txzt11uTJFss"
   },
   "source": [
    "## Visualize the Workflow\n",
    "\n",
    "Below is a generated diagram of the workflow using Mermaid syntax. It shows how each node connects in the graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "898b465a-b1a9-4afd-b47c-d9c4d35a5251",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "Qt89sV4kJFst",
    "outputId": "8a05f4c6-43a8-4e07-be11-75e1feb3ba72"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image, Markdown\n",
    "\n",
    "display(Image(compiled_support_agent.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a3d27a1-3300-47ce-8c17-af021b00f7be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "vVfgP2P9JFsv"
   },
   "source": [
    "## Helper Function to Run the Workflow\n",
    "\n",
    "This function takes a customer query and runs it through our compiled workflow, returning the final results (category, sentiment, and generated response)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fe32140-9cd4-44fa-bdb3-2acbd8899bb3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "O409_2mRJFsw"
   },
   "outputs": [],
   "source": [
    "def call_support_agent(agent, prompt, user_session_id, verbose=False):\n",
    "    events = agent.stream(\n",
    "        {\"customer_query\": prompt}, # initial state of the agent\n",
    "        {\"configurable\": {\"thread_id\": user_session_id}},\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "\n",
    "    print('Running Agent. Please wait...')\n",
    "    for event in events:\n",
    "        if verbose:\n",
    "                print(event)\n",
    "\n",
    "    display(Markdown(event['final_response']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b7914351-0ad2-469a-978c-ce78eae98531",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "0VeWUyGNJFsw"
   },
   "source": [
    "## Testing the Customer Support Workflow\n",
    "\n",
    "Let's test the workflow with some sample queries to verify categorization, sentiment analysis, and response generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aefb3d01-d183-4628-8d22-2fb65d4a4eac",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 205
    },
    "id": "s6v7AAnFlp8S",
    "outputId": "485003c1-ade1-4bcf-ddda-90ef64f65f36"
   },
   "outputs": [],
   "source": [
    "uid = 'jim001'\n",
    "query = \"do you support pre-trained models?\"\n",
    "call_support_agent(agent=compiled_support_agent,\n",
    "                   prompt=query,\n",
    "                   user_session_id=uid,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "514de91c-75c5-482d-8fc9-24ba9b63c2d6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "H4624wCxJFsx",
    "outputId": "e28b266b-711d-4e90-b8b5-5f4bb191b94b"
   },
   "outputs": [],
   "source": [
    "uid = 'jim002'\n",
    "query = \"how do I get my invoice?\"\n",
    "call_support_agent(agent=compiled_support_agent,\n",
    "                   prompt=query,\n",
    "                   user_session_id=uid,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3f52a8d1-d089-44ae-9ce2-3a89d64c9373",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 103
    },
    "id": "LIPGRwMJn5-q",
    "outputId": "fa378fd9-eecb-4d11-dbb6-3d11469ba809"
   },
   "outputs": [],
   "source": [
    "query = \"Can you tell me about your shipping policy?\"\n",
    "call_support_agent(agent=compiled_support_agent,\n",
    "                   prompt=query,\n",
    "                   user_session_id=uid,\n",
    "                   verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9541c40c-41b1-4986-a37f-41bfc7d8125a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "id": "FNspMHcJoBBx",
    "outputId": "b977019c-3823-473f-85da-e4aa87f5404a"
   },
   "outputs": [],
   "source": [
    "query = \"I'm fed up with this faulty hardware, I need a refund\"\n",
    "call_support_agent(agent=compiled_support_agent,\n",
    "                   prompt=query,\n",
    "                   user_session_id=uid,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "812e3079-4e30-4acb-9540-5ddcb0888859",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 188
    },
    "id": "BMzoQZsBNY9n",
    "outputId": "1649789d-7ee2-4fc2-a487-ca64b2705674"
   },
   "outputs": [],
   "source": [
    "query = \"What are your working hours?\"\n",
    "call_support_agent(agent=compiled_support_agent,\n",
    "                   prompt=query,\n",
    "                   user_session_id=uid,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9ec384cf-6adc-459c-a018-0a8fa4029a88",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = \"What have I asked you till now\"\n",
    "call_support_agent(agent=compiled_support_agent,\n",
    "                   prompt=query,\n",
    "                   user_session_id=uid,\n",
    "                   verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "30c957f8-6680-4cba-ac02-691f5dd5a972",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def create_tf_serving_json(data):\n",
    "    return {'inputs': {name: data[name].tolist() for name in data.keys()} if isinstance(data, dict) else data.tolist()}\n",
    "\n",
    "def score_model(dataset):\n",
    "    url = 'https://fe-vm-agentic-ai.cloud.databricks.com/serving-endpoints/customer_support_agent/invocations'\n",
    "    headers = {'Authorization': f'Bearer {os.environ.get(\"DATABRICKS_TOKEN\")}', 'Content-Type': 'application/json'}\n",
    "    ds_dict = {'dataframe_split': dataset.to_dict(orient='split')} if isinstance(dataset, pd.DataFrame) else create_tf_serving_json(dataset)\n",
    "    data_json = json.dumps(ds_dict, allow_nan=True)\n",
    "    response = requests.request(method='POST', headers=headers, url=url, data=data_json)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f'Request failed with status {response.status_code}, {response.text}')\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0bf586e8-89f2-444c-9fc0-915066ef7291",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M5_Project_ Build_a_Customer_Support_Router_Agentic_RAG_System",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
