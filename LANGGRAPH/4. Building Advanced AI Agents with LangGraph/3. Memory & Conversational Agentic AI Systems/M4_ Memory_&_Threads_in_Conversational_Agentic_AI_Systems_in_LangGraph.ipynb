{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b48b3082-ccfc-4409-aa2e-58c6a2a99fad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "50fa7f8a-8764-4bb9-9968-48b681a0e4f1"
   },
   "source": [
    "# Memory & Threads in Conversational Agentic AI Systems in LangGraph\n",
    "\n",
    "Every interaction between the user and the agentic system is in isolation and a new request without keep track of past historical conversations (by default). By leveraging memory and threads we can make our agentic system conversational.\n",
    "\n",
    "![](https://i.imgur.com/nJn1o09.png)\n",
    "\n",
    "#### Memory in LangGraph:\n",
    "\n",
    "- Utilizes a built-in persistence layer to maintain graph state across executions.\n",
    "- Enables features like human-in-the-loop interactions, time travel, fault tolerance and conversational capabilities\n",
    "\n",
    "#### Threads:\n",
    "\n",
    "- Serve as unique identifiers for sequences of checkpoints (agent state snapshots).\n",
    "- Allow retrieval and management of graph states post-execution.\n",
    "- Specified during graph invocation via {\"configurable\": {\"thread_id\": \"user-session-id\"}}.\n",
    "- User session id can be generated and assigned per unique user or user session\n",
    "- This is used by the agent to refer to past conversation and agent state history for any user session at any time\n",
    "- Enables multi-user conversation for your agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ede91809-5708-48fc-aaf3-222ebe93cb7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ff151ef1-fa30-482a-94da-8f49964afbc3",
    "outputId": "9a9782b6-15f3-49a0-92d7-7bd3c4d696b1"
   },
   "outputs": [],
   "source": [
    "!pip install langchain==0.3.14\n",
    "!pip install langchain-openai==0.3.0\n",
    "!pip install langchain-community==0.3.14\n",
    "!pip install langgraph==0.2.64\n",
    "!pip install langgraph-checkpoint-sqlite==2.0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e81b462-0323-4876-ad62-28831c4cfddf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "H9c37cLnSrbg"
   },
   "source": [
    "## Enter Open AI API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4bf75689-9dc2-422f-9d94-ae18ee8f2bd6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv3JzCEx_PAd",
    "outputId": "4fb5bfa8-8585-4a59-d7a9-1840c6f95983"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "OPENAI_KEY = getpass('Enter Open AI API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33aed9be-1e9d-4349-8e27-ca2c3e5dae7b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "ucWRRI3QztL2"
   },
   "source": [
    "## Enter Tavily Search API Key\n",
    "\n",
    "Get a free API key from [here](https://tavily.com/#api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4c073b92-9c99-455f-a303-e8f04f31bff7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mK-1WLzOrJdb",
    "outputId": "e4e2c581-b3c7-4051-fc71-1ec621fc6882"
   },
   "outputs": [],
   "source": [
    "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5a9b842b-0741-4323-9d96-4eb1cae5db17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "1T0s0um5Svfa"
   },
   "source": [
    "## Setup Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0e282fe7-9d65-4e29-b9cc-b2492823fc36",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "x1YSuHNF_lbh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e5d87858-450e-4264-b8d5-22c211588577",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "5999f8d0-989f-4638-8ade-5c257cbadfe8"
   },
   "source": [
    "## State\n",
    "\n",
    "First, define the [State](https://langchain-ai.github.io/langgraph/concepts/low_level/#state) of the graph.\n",
    "\n",
    "The State schema serves as the input schema for all Nodes and Edges in the graph.\n",
    "\n",
    "Let's use the `TypedDict` class from python's `typing` module as our schema, which provides type hints for the keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d8f3457d-44eb-4fe4-be93-d370dd557fbb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "6a90709b-ddfa-4671-8acc-c59969a29991"
   },
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7015c09b-ccee-431e-922f-c0a5dedcfcee",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "mMwPwbV-mNQm"
   },
   "source": [
    "## Augment the LLM with tools\n",
    "\n",
    "Here we define our custom search tool and then bind it to the LLM to augment the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f7ff22ed-5cd7-49f0-be4b-6db423a761b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "2lYXBn1ImzlB"
   },
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "tavily_search = TavilySearchAPIWrapper()\n",
    "@tool\n",
    "def search_web(query: str, num_results=5):\n",
    "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
    "    results = tavily_search.raw_results(query=query,\n",
    "                                        max_results=num_results,\n",
    "                                        search_depth='advanced',\n",
    "                                        include_raw_content=True)\n",
    "    return results\n",
    "\n",
    "tools = [search_web]\n",
    "llm_with_tools = llm.bind_tools(tools=tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bce3e86c-eec7-4a7b-ae74-2a52a19a7491",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "rTw_Jl2Ay-Wv"
   },
   "source": [
    "## Build Agentic Graph with In-Memory Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7bc2650f-b120-432d-a188-2e3605a49a08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "IJvHs_Py3uCV"
   },
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "\n",
    "# Augmented LLM with Tools Node function\n",
    "def tool_calling_llm(state: State) -> State:\n",
    "    current_state = state[\"messages\"]\n",
    "    return {\"messages\": [llm_with_tools.invoke(current_state)]}\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
    "builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "builder.add_edge(START, \"tool_calling_llm\")\n",
    "\n",
    "# Conditional Edge\n",
    "builder.add_conditional_edges(\n",
    "    \"tool_calling_llm\",\n",
    "    # If the latest message (result) from LLM is a tool call -> tools_condition routes to tools\n",
    "    # If the latest message (result) from LLM is a not a tool call -> tools_condition routes to END\n",
    "    tools_condition,\n",
    "    [\"tools\", END]\n",
    ")\n",
    "builder.add_edge(\"tools\", \"tool_calling_llm\") # this is the key feedback loop\n",
    "builder.add_edge(\"tools\", END)\n",
    "\n",
    "# add in-memory persistence (transient memory)\n",
    "memory = MemorySaver()\n",
    "agent_inmem = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "fed8e829-6031-4e88-a1b9-258498aa2fc4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "JR2L3D5Y3uH9",
    "outputId": "23dc27c8-ff97-481a-f66d-9f7cc7e4b82b"
   },
   "outputs": [],
   "source": [
    "agent_inmem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74f74690-88b7-49b2-80e9-99e007f19469",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "GAD8KmlMzIyf"
   },
   "source": [
    "## Test Agent with In-Memory Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dce92479-e403-4328-b132-98d9ec459e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tK72RDhVioTg"
   },
   "outputs": [],
   "source": [
    "uid = 'user001'\n",
    "config = {\"configurable\": {\"thread_id\": uid}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3ba7f4e8-985b-4cea-a422-3caf28e4cd0e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "db16ab8d-b817-4f3a-befc-a02b579c4fca",
    "outputId": "51294aa9-126f-4ea5-f954-93a713fae619"
   },
   "outputs": [],
   "source": [
    "user_input = \"Explain AI in 1 line\"\n",
    "for event in agent_inmem.stream(input={\"messages\": user_input},\n",
    "                          config=config,\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f8fa3a9e-f3b2-453e-9339-ed70d08389b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jmYdoTzijjtI",
    "outputId": "a39533c4-0c0c-4aff-b994-c3c94cd8ad01"
   },
   "outputs": [],
   "source": [
    "user_input = \"Do the same for ML\"\n",
    "for event in agent_inmem.stream(input={\"messages\": user_input},\n",
    "                          config=config,\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f30ea05e-d18b-4684-b2be-feb1b5def62a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JyqTE_xEjQe2",
    "outputId": "bba9238c-113e-445b-d246-d4e1587703a4"
   },
   "outputs": [],
   "source": [
    "agent_inmem.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d2b47ce4-7510-459f-95a5-9a094418d97d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2YpHddsTjpU4",
    "outputId": "4e5e83a4-ce10-4831-ac67-e114a449cc17"
   },
   "outputs": [],
   "source": [
    "history = list(agent_inmem.get_state_history(config))\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "42e3ed20-d3c2-4490-80ee-20ea8c010636",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "CfCJixCRluQ_"
   },
   "outputs": [],
   "source": [
    "uid = 'user002'\n",
    "config = {\"configurable\": {\"thread_id\": uid}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c435c99c-f064-4ca1-8b22-c4e0d62abaff",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "h-zYQrB6383i",
    "outputId": "861c5789-7696-4922-ce1b-cfbea0ef7bc7"
   },
   "outputs": [],
   "source": [
    "user_input = \"Tell me 3 latest OpenAI product releases\"\n",
    "for event in agent_inmem.stream(input={\"messages\": user_input},\n",
    "                          config=config,\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e657b75b-10e4-424f-8980-79f0a3c51ce6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMDzsaKDmInw",
    "outputId": "9a0b6df5-04ab-422f-eb37-47dde083451d"
   },
   "outputs": [],
   "source": [
    "user_input = \"do the same for Meta releases\"\n",
    "for event in agent_inmem.stream(input={\"messages\": user_input},\n",
    "                          config=config,\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b17ec79-2441-4bdc-a60f-e0a23778f9f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fu64HhjUQEE9",
    "outputId": "fb5c7bf1-d37f-43ad-80c2-84ef2094a420"
   },
   "outputs": [],
   "source": [
    "uid = 'user001'\n",
    "config = {\"configurable\": {\"thread_id\": uid}}\n",
    "user_input = \"what did we discuss so far\"\n",
    "for event in agent_inmem.stream(input={\"messages\": user_input},\n",
    "                          config=config,\n",
    "                          stream_mode='values'):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "037873cd-3347-4246-a5fe-b94e54d4b691",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "v76pq5jgzeD4"
   },
   "source": [
    "## Build & Test Agentic Graph with On-disk Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "905390fd-c75f-4f9b-9827-621013174917",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Aqb4M8-qzhGT",
    "outputId": "5ea34110-e8e7-4094-f1e9-d93645f94446"
   },
   "outputs": [],
   "source": [
    "# clearing memory database (just for demo, in general should keep it)\n",
    "!rm memory.db*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0919a8aa-5747-4ea4-b47d-4b7c6b86b574",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "tH4tF0obz9E4"
   },
   "outputs": [],
   "source": [
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "\n",
    "def call_conversational_agent(agent_graph, prompt, user_session_id):\n",
    "    with SqliteSaver.from_conn_string(\"memory.db\") as memory:\n",
    "        agent_extmem = agent_graph.compile(checkpointer=memory)\n",
    "        for event in agent_extmem.stream(input={\"messages\": prompt},\n",
    "                                         config={\"configurable\": {\"thread_id\": user_session_id}},\n",
    "                                         stream_mode='values'):\n",
    "            event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ca3d94d-77b0-4798-b931-cdd93ccb75bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mAJAO3ut0ujO",
    "outputId": "4131dbf4-12c1-48bb-bf5c-dceff5a2d1e8"
   },
   "outputs": [],
   "source": [
    "builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d7004229-593b-4d21-9f30-5afbb524b0c4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gf1NsjUa0ntz",
    "outputId": "68205299-2164-4b00-bafd-44ac0fcbfab6"
   },
   "outputs": [],
   "source": [
    "uid = 'bond007'\n",
    "prompt = \"What is the latest news on Apple? summarize in 3 bullets\"\n",
    "call_conversational_agent(agent_graph=builder,\n",
    "                          prompt=prompt,\n",
    "                          user_session_id=uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84c26979-00e7-4cff-aa38-f28c7e52089b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xaLLJWQv1D5V",
    "outputId": "7b8a5d06-3c9e-460f-e5ea-f21588279b51"
   },
   "outputs": [],
   "source": [
    "prompt = \"What about microsoft?\"\n",
    "call_conversational_agent(agent_graph=builder,\n",
    "                          prompt=prompt,\n",
    "                          user_session_id=uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5040ffc-4e91-428f-8f1a-6ca07b34890c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "oLuJa5II1GaR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M4_ Memory_&_Threads_in_Conversational_Agentic_AI_Systems_in_LangGraph",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
