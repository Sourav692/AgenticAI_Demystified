{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cf007d4c-4412-4109-8f36-7262ce38786c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "8pdRDlVs1MJs"
   },
   "source": [
    "# Build a Financial Analyst Tool-Use AI Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "977fa40b-4b2c-4b34-af61-25906e1fdeae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "NYBpZTjLnEXb"
   },
   "source": [
    "This project will focus on building a Tool-Use Agentic AI System which acts as a Financial Analyst & Advisor.\n",
    "\n",
    "![](https://i.imgur.com/sHevAT8.png)\n",
    "\n",
    "\n",
    "### Financial Analyst Tool-Use Agentic AI System\n",
    "\n",
    "In this project, we will design a **Financial Analyst Tool-Use Agentic AI System** to assist investors with accurate, up-to-date stock market insights. We will be building the complete agent from scratch using **LangGraph**, a cutting-edge alternative to LangChain. The workflow comprises the following components:\n",
    "\n",
    "1. **Agent System Prompt**:\n",
    "   - The agent is designed to validate input queries for relevance and specificity.\n",
    "   - It provides comprehensive market analysis or stock-specific insights depending on the user's query.\n",
    "   - For invalid queries, the agent responds professionally and guides the user appropriately.\n",
    "\n",
    "\n",
    "   **Flows**:\n",
    "   - **Flow 1**: For general market trends, the agent analyzes data and suggests stock opportunities using tools like `SEARCH_WEB` and `GET_GENERAL_MARKET_DATA`.\n",
    "   - **Flow 2**: For stock-specific queries, the agent validates the stock ticker, retrieves relevant data, and provides insights using tools such as `GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS` and `GET_STOCK_PRICE_METRICS`.\n",
    "\n",
    "2. **Financial Analysis Tools**:\n",
    "   The system integrates multiple tools to get useful financial data and metrics:\n",
    "   - **SEARCH_WEB**: Fetches general stock market information from the web.\n",
    "   - **GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS**: Provides insights into key financial metrics such as P/E ratio, ROE, etc.\n",
    "   - **GET_STOCK_NEWS**: Extracts the latest news and updates related to stocks or markets.\n",
    "   - **GET_GENERAL_MARKET_DATA**: Fetches data on overall market trends and performance.\n",
    "   - **GET_STOCK_TICKER**: Validates and fetches stock ticker symbols based on user queries.\n",
    "   - **GET_STOCK_PRICE_METRICS**: Retrieves price trends, performance, and metrics for specific stocks.\n",
    "\n",
    "3. **Stock Market Data Providers**:\n",
    "   The system ensures real-time, reliable data by integrating with top providers like Yahoo Finance, Finviz, TMX, Cboe, and more, through platforms like **OpenBB**.\n",
    "\n",
    "4. **Message Trimmer**:\n",
    "   A newly introduced component trims agent state message history to ensure they are well within the context window limit of the LLM.\n",
    "\n",
    "5. **Tool-Use Agentic Framework**:\n",
    "   The system employs **ReAct reasoning**, combining logical reasoning with dynamic tool usage. This framework ensures precise and actionable results by dynamically selecting the right tools based on the query.\n",
    "\n",
    "6. **Final Response**:\n",
    "   After processing the data from tool calls, the agentic system generates the final response.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "99252462-c655-4327-95f0-81e2ff2ca569",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "L1KvMtf54l0d"
   },
   "source": [
    "## Install OpenAI, LangGraph and LangChain dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ed6b158-71f0-4d95-87d4-18bda3cea833",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2evPp14fy258",
    "outputId": "5ea12113-e034-4ee1-8289-7f6e6c8f957d"
   },
   "outputs": [],
   "source": [
    "!pip install -q langchain==0.3.14\n",
    "!pip install -q langchain-openai==0.3.0\n",
    "!pip install -q langchain-community==0.3.14\n",
    "!pip install -q langgraph==0.2.64\n",
    "# fix yfinance to stable version\n",
    "!pip install -q yfinance==0.2.51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ed452f0a-362d-4e25-83e9-a8ec08b864e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install -U -qqqq databricks-langchain uv databricks-agents mlflow-skinny[databricks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8c6f394-d663-4d45-abb4-ae3d3f3acaa8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d8e9bef2-8b38-4d84-8b8c-78a8ca93767f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "id": "pSE8EoRXyuxx"
   },
   "source": [
    "## Install OpenBB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef46a362-8580-4c18-9237-d317788efb0b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "fO4gOIVIjGH7",
    "outputId": "fb20e45e-8f94-432b-adcc-4df8156687c3"
   },
   "outputs": [],
   "source": [
    "!pip install -q openbb[all]==4.3.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f8f4177d-e1d9-4da2-9221-5ffb401c14b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.library.restartPython()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0f2b4126-58e7-454c-b771-451292e1489e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%%writefile agent.py\n",
    "\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Annotated, Any, Generator, Optional, Sequence, Union\n",
    "from uuid import uuid4\n",
    "import os\n",
    "\n",
    "from openbb import obb\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "import mlflow\n",
    "from databricks_langchain import ChatDatabricks, UCFunctionToolkit, VectorSearchRetrieverTool\n",
    "from langchain_core.language_models import LanguageModelLike\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    BaseMessage,\n",
    "    convert_to_openai_messages,\n",
    "    HumanMessage,\n",
    "    SystemMessage,\n",
    "    RemoveMessage,\n",
    "    trim_messages,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig, RunnableLambda\n",
    "from langchain_core.tools import BaseTool, tool\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt.tool_node import ToolNode\n",
    "from langgraph.prebuilt import tools_condition\n",
    "from mlflow.entities import SpanType\n",
    "from mlflow.pyfunc import ResponsesAgent\n",
    "from mlflow.types.responses import (\n",
    "    ResponsesAgentRequest,\n",
    "    ResponsesAgentResponse,\n",
    "    ResponsesAgentStreamEvent,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "from pyspark.dbutils import DBUtils\n",
    "\n",
    "from databricks.sdk.runtime import *\n",
    "\n",
    "dbutils = DBUtils(spark)\n",
    "\n",
    "################################################################################\n",
    "# Open AI API Key\n",
    "################################################################################\n",
    "OPENAI_KEY = dbutils.secrets.get(scope=\"AgenticAI\", key=\"OPENAI_KEY\")\n",
    "\n",
    "################################################################################\n",
    "# Enter OpenBB Key\n",
    "# Get a free API key from (https://my.openbb.co/app/platform/pat)\n",
    "################################################################################\n",
    "OPENBB_PAT = dbutils.secrets.get(scope=\"AgenticAI\", key=\"OPENBB_PAT\")\n",
    "\n",
    "################################################################################\n",
    "# Enter Tavily Search API Key\n",
    "# Get a free API key from (https://tavily.com/#api)\n",
    "################################################################################\n",
    "OPENBB_PAT = dbutils.secrets.get(scope=\"AgenticAI\", key=\"OPENBB_PAT\")\n",
    "\n",
    "################################################################################\n",
    "# Enter Tavily Search API Key\n",
    "# Get a free API key from (https://tavily.com/#api)\n",
    "################################################################################\n",
    "TAVILY_API_KEY = dbutils.secrets.get(scope=\"AgenticAI\", key=\"TAVILY_API_KEY\")\n",
    "\n",
    "################################################################################\n",
    "# Setup Environment Variables\n",
    "################################################################################\n",
    "os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
    "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY\n",
    "\n",
    "################################################################################\n",
    "# Enter OBB Keys\n",
    "################################################################################\n",
    "obb.user.credentials.fmp_api_key = dbutils.secrets.get(scope=\"AgenticAI\", key=\"fmp_api_key\")\n",
    "obb.user.credentials.polygon_api_key = dbutils.secrets.get(scope=\"AgenticAI\", key=\"polygon_api_key\")\n",
    "\n",
    "################################################################################\n",
    "# Create Financial Tools\n",
    "# Financial Analysis Tools: The system integrates multiple tools to get useful financial data and metrics:\n",
    "\n",
    "# SEARCH_WEB: Fetches general stock market information from the web.\n",
    "# GET_STOCK_FUNDAMENTAL_INDICATOR_METRICS: Provides insights into key financial metrics such as P/E ratio, ROE, etc.\n",
    "# GET_STOCK_NEWS: Extracts the latest news and updates related to stocks or markets.\n",
    "# GET_GENERAL_MARKET_DATA: Fetches data on overall market trends and performance.\n",
    "# GET_STOCK_TICKER: Validates and fetches stock ticker symbols based on user queries.\n",
    "# GET_STOCK_PRICE_METRICS: Retrieves price trends, performance, and metrics for specific stocks.\n",
    "################################################################################\n",
    "tavily_search = TavilySearchAPIWrapper()\n",
    "\n",
    "@tool\n",
    "def search_web(query: str, num_results=8) -> list:\n",
    "    \"\"\"Search the web for a query. Userful for general information or general news\"\"\"\n",
    "    results = tavily_search.raw_results(query=query,\n",
    "                                        max_results=num_results,\n",
    "                                        search_depth='advanced',\n",
    "                                        include_answer=False,\n",
    "                                        include_raw_content=True)\n",
    "    return results\n",
    "\n",
    "@tool\n",
    "def get_stock_ticker_symbol(stock_name: str) -> str:\n",
    "    \"\"\"Get the symbol, name and CIK for any publicly traded company\"\"\"\n",
    "    # Use OpenBB to search for stock ticker symbol and company details by name.\n",
    "    # The provider \"sec\" fetches data from the U.S. Securities and Exchange Commission (SEC).\n",
    "    res = obb.equity.search(stock_name, provider=\"sec\")\n",
    "\n",
    "    # Convert the result to a DataFrame and format it as markdown for readability.\n",
    "    stock_ticker_details = res.to_df().to_markdown()\n",
    "\n",
    "    # Prepare the output with the stock details.\n",
    "    output = \"\"\"Here are the details of the company and its stock ticker symbol:\\n\\n\"\"\" + stock_ticker_details\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_stock_price_metrics(stock_ticker: str) -> str:\n",
    "    \"\"\"Get historical stock price data, stock price quote and price performance data\n",
    "       like price changes for a specific stock ticker\"\"\"\n",
    "\n",
    "    # Fetch the latest stock price quote using \"cboe\" provider.\n",
    "    res = obb.equity.price.quote(stock_ticker, provider='cboe')\n",
    "    price_quote = res.to_df().to_markdown()\n",
    "\n",
    "    # Retrieve stock price performance metrics (e.g., percentage change) using \"finviz\" provider.\n",
    "    res = obb.equity.price.performance(symbol=stock_ticker, provider='finviz')\n",
    "    price_performance = res.to_df().to_markdown()\n",
    "\n",
    "    # Fetch historical price data for the past year using \"yfinance\" provider.\n",
    "    end_date = datetime.now()\n",
    "    start_date = (end_date - timedelta(days=365)).strftime(\"%Y-%m-%d\")\n",
    "    res = obb.equity.price.historical(symbol=stock_ticker, start_date=start_date,\n",
    "                                      interval='1d', provider='yfinance')\n",
    "    price_historical = res.to_df().to_markdown()\n",
    "\n",
    "    # Combine the results into a formatted output.\n",
    "    output = (\"\"\"Here are the stock price metrics and data for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" +\n",
    "              \"Price Quote Metrics:\\n\\n\" + price_quote +\n",
    "              \"\\n\\nPrice Performance Metrics:\\n\\n\" + price_performance +\n",
    "              \"\\n\\nPrice Historical Data:\\n\\n\" + price_historical)\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_stock_fundamental_indicator_metrics(stock_ticker: str) -> str:\n",
    "    \"\"\"Get fundamental indicator metrics for a specific stock ticker\"\"\"\n",
    "\n",
    "    # Retrieve fundamental financial ratios (e.g., P/E ratio, ROE) using \"fmp\" provider.\n",
    "    res = obb.equity.fundamental.ratios(symbol=stock_ticker, period='annual',\n",
    "                                        limit=10, provider='fmp')\n",
    "    fundamental_ratios = res.to_df().to_markdown()\n",
    "\n",
    "    # Fetch additional fundamental metrics (e.g., EBITDA, revenue growth) using \"yfinance\" provider.\n",
    "    res = obb.equity.fundamental.metrics(symbol=stock_ticker, period='annual',\n",
    "                                        limit=10, provider='yfinance')\n",
    "    fundamental_metrics = res.to_df().to_markdown()\n",
    "\n",
    "    # Combine fundamental ratios and metrics into a single output.\n",
    "    output = (\"\"\"Here are the fundamental indicator metrics and data for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" +\n",
    "              \"Fundamental Ratios:\\n\\n\" + fundamental_ratios +\n",
    "              \"\\n\\nFundamental Metrics:\\n\\n\" + fundamental_metrics)\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_stock_news(stock_ticker: str) -> str:\n",
    "    \"\"\"Get news article headlines for a specific stock ticker\"\"\"\n",
    "\n",
    "    # Define the date range to fetch news (last 45 days).\n",
    "    end_date = datetime.now()\n",
    "    start_date = (end_date - timedelta(days=45)).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    # Retrieve news headlines for the stock using \"tmx\" provider.\n",
    "    # res = obb.news.company(symbol=stock_ticker, start_date=start_date, provider='tmx', limit=50)\n",
    "    # Change the provide to Polygon. As tmx now support only CANADA Companies\n",
    "    res = obb.news.company(symbol=stock_ticker, start_date=start_date, provider='polygon', limit=50)\n",
    "    news = res.to_df()\n",
    "\n",
    "    # Extract relevant columns (symbols and titles) and format as markdown.\n",
    "    news = news[['symbols', 'title']].to_markdown()\n",
    "\n",
    "    # Prepare the output with the news headlines.\n",
    "    output = (\"\"\"Here are the recent news headlines for the stock ticker symbol \"\"\" + stock_ticker + \"\"\": \\n\\n\"\"\" + news)\n",
    "    return output\n",
    "\n",
    "@tool\n",
    "def get_general_market_data() -> str:\n",
    "    \"\"\"Get general data and indicators for the whole stock market including,\n",
    "       most actively traded stocks based on volume, top price gainers and top price losers.\n",
    "       Useful when you want an overview of the market and what stocks to look at.\"\"\"\n",
    "\n",
    "    # Retrieve the most actively traded stocks using \"yfinance\" provider.\n",
    "    res = obb.equity.discovery.active(sort='desc', provider='yfinance', limit=15)\n",
    "    most_active_stocks = res.to_df().to_markdown()\n",
    "\n",
    "    # Fetch the top price gainers using \"yfinance\" provider.\n",
    "    res = obb.equity.discovery.gainers(sort='desc', provider='yfinance', limit=15)\n",
    "    price_gainers = res.to_df().to_markdown()\n",
    "\n",
    "    # Retrieve the top price losers using \"yfinance\" provider.\n",
    "    res = obb.equity.discovery.losers(sort='desc', provider='yfinance', limit=15)\n",
    "    price_losers = res.to_df().to_markdown()\n",
    "\n",
    "    # Combine the market data into a single formatted output.\n",
    "    output = (\"\"\"Here's some detailed information of the stock market which includes most actively traded stocks, gainers and losers:\\n\\n\"\"\" +\n",
    "              \"Most actively traded stocks:\\n\\n\" + most_active_stocks +\n",
    "              \"\\n\\nTop price gainers:\\n\\n\" + price_gainers +\n",
    "              \"\\n\\nTop price losers:\\n\\n\" + price_losers)\n",
    "    return output\n",
    "\n",
    "################################################################################\n",
    "# Define Your System Prompt\n",
    "################################################################################\n",
    "AGENT_SYS_PROMPT = \"\"\"Role: You are an AI stock market assistant tasked with providing investors\n",
    "with up-to-date, detailed information on individual stocks or advice based on general market data.\n",
    "\n",
    "Objective: Assist data-driven stock market investors by giving accurate,\n",
    "complete, but concise information relevant to their questions about individual\n",
    "stocks or general advice on useful stocks based on general market data and trends.\n",
    "\n",
    "Capabilities: You are given a number of tools as functions. Use as many tools\n",
    "as needed to ensure all information provided is timely, accurate, concise,\n",
    "relevant, and responsive to the user's query.\n",
    "\n",
    "Starting Flow:\n",
    "Input validation: Determine if the input is asking about a specific company\n",
    "or stock ticker (Flow 2). If not, check if they are asking for general advice on potentially useful stocks\n",
    "based on current market data (Flow 1). Otherwise, respond in a friendly, positive, professional tone\n",
    "that you don't have information to answer as you can only provide financial advice based on market data.\n",
    "For each of the flows related to valid questions use the following instructions:\n",
    "\n",
    "Flow 1:\n",
    "A. Market Analysis: If the query is valid and the user wants to get general advice on the market\n",
    "or stocks worth looking into for investing, leverage the general market data tool to get relevant data.\n",
    "In case you need more information then you can also use web search.\n",
    "\n",
    "Flow 2:\n",
    "A. Symbol extraction. If the query is valid and is related to a specific company or companies,\n",
    "extract the company name or ticker symbol from the question.\n",
    "If a company name is given, look up the ticker symbol using a tool.\n",
    "If the ticker symbol is not found based on the company, try to\n",
    "correct the spelling and try again, like changing \"microsfot\" to \"microsoft\",\n",
    "or broadening the search, like changing \"southwest airlines\" to a shorter variation\n",
    "like \"southwest\" and increasing \"limit\" to 10 or more. If the company or ticker is\n",
    "still unclear based on the question or conversation so far, and the results of the\n",
    "symbol lookup, then ask the user to clarify which company or ticker.\n",
    "\n",
    "B. Information retrieval. Determine what data the user is seeking on the symbol\n",
    "identified. Use the appropriate tools to fetch the requested information. Only use\n",
    "data obtained from the tools. You may use multiple tools in a sequence. For instance,\n",
    "first determine the company's symbol, then retrieve price data using the symbol\n",
    "and fundamental indicator data etc. For specific queries only retrieve data using the most relevant tool.\n",
    "If detailed analysis is needed, you can call multiple tools to retrieve data first.\n",
    "In case you still need more information then you can also use web search.\n",
    "\n",
    "Response Generation Flow:\n",
    "Compose Response: Analyze the retrieved data carefully and provide a comprehensive answer to the user in a clear and concise format,\n",
    "in a friendly professional tone, emphasizing the data retrieved.\n",
    "If the user asks for recommendations you can give some recommendations\n",
    "but emphasize the user to do their own research before investing.\n",
    "When generating the final response in markdown,\n",
    "if there are special characters in the text, such as the dollar symbol,\n",
    "ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\n",
    "\n",
    "Example Interaction:\n",
    "User asks: \"What is the PE ratio for Eli Lilly?\"\n",
    "Chatbot recognizes 'Eli Lilly' as a company name.\n",
    "Chatbot uses symbol lookup to find the ticker for Eli Lilly, returning LLY.\n",
    "Chatbot retrieves the PE ratio using the proper function with symbol LLY.\n",
    "Chatbot responds: \"The PE ratio for Eli Lilly (symbol: LLY) as of May 12, 2024 is 30.\"\n",
    "\n",
    "Check carefully and only call the tools which are specifically named below.\n",
    "Only use data obtained from these tools.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# just checking size of the system prompt so we do not cross 128K context window limit when trimming messages later\n",
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")\n",
    "tokens = enc.encode(AGENT_SYS_PROMPT)\n",
    "print(f\"Number of tokens: {len(tokens)}\")\n",
    "\n",
    "################################################################################\n",
    "# Key Steps For Agent Creation\n",
    "# State Definition:\n",
    "\n",
    "# The State class defines the structure of the conversation state, which holds the list of messages.\n",
    "# Tools Setup:\n",
    "\n",
    "# The tools list contains functions the agent can use to fetch data or perform actions (e.g., stock data, web search).\n",
    "# LLM Initialization:\n",
    "\n",
    "# The ChatOpenAI instance is initialized with GPT-4o and bound to the tools, enabling the agent to use them when needed.\n",
    "# Chatbot Node:\n",
    "\n",
    "# The chatbot function processes user input, trims the conversation history to avoid exceeding token limits, and generates a response using the LLM.\n",
    "# Tool Node:\n",
    "\n",
    "# The ToolNode handles the execution of tools when the agent decides to use them (e.g., fetching stock prices or searching the web).\n",
    "# Graph Construction:\n",
    "\n",
    "# The graph is built by adding nodes (chatbot and tools) and edges, with conditional logic to decide when to use tools or end the conversation.\n",
    "# Agent Compilation:\n",
    "\n",
    "# The graph is compiled into a runnable agent (financial_analyst_agent), which can process user inputs and interact with tools as needed.\n",
    "################################################################################\n",
    "\n",
    "################################################################################\n",
    "# Define your LLM endpoint\n",
    "################################################################################\n",
    "# llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "# LLM_ENDPOINT_NAME = \"databricks-gpt-oss-120b\"\n",
    "LLM_ENDPOINT_NAME = \"databricks-claude-3-7-sonnet\"\n",
    "llm = ChatDatabricks(endpoint=LLM_ENDPOINT_NAME)\n",
    "\n",
    "################################################################################\n",
    "# Define the state of the graph, which holds the conversation messages\n",
    "################################################################################\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "###############################################################################\n",
    "## Define tools for your agent, enabling it to retrieve data or take actions\n",
    "## beyond text generation\n",
    "## To create and see usage examples of more tools, see\n",
    "## https://docs.databricks.com/en/generative-ai/agent-framework/agent-tool.html\n",
    "###############################################################################\n",
    "tools = [\n",
    "    get_stock_ticker_symbol,\n",
    "    get_stock_price_metrics,\n",
    "    get_stock_fundamental_indicator_metrics,\n",
    "    get_stock_news,\n",
    "    search_web,\n",
    "    get_general_market_data\n",
    "]\n",
    "\n",
    "###############################################################################\n",
    "# Create Tool-Calling Agent with Language Model and Tools\n",
    "###############################################################################\n",
    "def create_tool_calling_agent(\n",
    "    llm: LanguageModelLike,\n",
    "    tools: list,\n",
    "    system_prompt: Optional[str] = None,\n",
    "):\n",
    "    \"\"\"Create a tool-calling agent that uses the given model and tools.\n",
    "\n",
    "    Args:\n",
    "        llm (LanguageModelLike): The language model to use for the agent.\n",
    "        tools (list): A list of tools the agent can use.\n",
    "        system_prompt (Optional[str]): An optional system prompt to guide the agent's behavior.\n",
    "\n",
    "    Returns:\n",
    "        A tool-calling agent that can use the given model and tools.\n",
    "    \"\"\"\n",
    "    # Create a chat model with the given model and tools\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    # System message to guide the agent's behavior\n",
    "    SYS_MSG = SystemMessage(content=AGENT_SYS_PROMPT)\n",
    "\n",
    "    def chatbot(state: State):\n",
    "        # Trim messages to avoid exceeding token limits\n",
    "        messages = trim_messages(\n",
    "            state[\"messages\"],\n",
    "            max_tokens=127000,\n",
    "            strategy=\"last\", # keep last 127K tokens in messages\n",
    "            token_counter=ChatOpenAI(model=\"gpt-4o\"),\n",
    "            include_system=True, # keep system message always\n",
    "            allow_partial=True, # trim messages to partial content if needed\n",
    "\n",
    "        )\n",
    "        # Invoke the LLM with the system message and trimmed conversation history\n",
    "        return {\"messages\": [llm_with_tools.invoke([SYS_MSG] + messages)]}\n",
    "    \n",
    "    # Initialize the graph builder with the defined state\n",
    "    graph_builder = StateGraph(State)\n",
    "\n",
    "    # Add the chatbot node to the graph\n",
    "    graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "    # Add a node for executing tools (e.g., fetching data, searching the web)\n",
    "    tool_node = ToolNode(tools=tools)\n",
    "    graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "    # Add conditional edges: the chatbot decides whether to use tools or end the conversation\n",
    "    graph_builder.add_conditional_edges(\n",
    "        \"chatbot\",\n",
    "        tools_condition,\n",
    "        ['tools', END]\n",
    "    )\n",
    "\n",
    "    # After using a tool, return to the chatbot to decide the next step\n",
    "    graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "    # Set the chatbot as the entry point of the graph\n",
    "    graph_builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "    # Compile the graph into a runnable agent\n",
    "    financial_analyst_agent = graph_builder.compile()\n",
    "\n",
    "    return financial_analyst_agent\n",
    "\n",
    "###############################################################################\n",
    "# Convert Responses to ChatCompletion Messages\n",
    "###############################################################################\n",
    "class LangGraphResponsesAgent(ResponsesAgent):\n",
    "    def __init__(self, agent):\n",
    "        self.agent = agent\n",
    "\n",
    "    def _responses_to_cc(self, message: dict[str, Any]) -> list[dict[str, Any]]:\n",
    "        \"\"\"Convert from a Responses API output item to ChatCompletion messages.\"\"\"\n",
    "        msg_type = message.get(\"type\")\n",
    "        if msg_type == \"function_call\":\n",
    "            return [\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"content\": \"tool call\",\n",
    "                    \"tool_calls\": [\n",
    "                        {\n",
    "                            \"id\": message[\"call_id\"],\n",
    "                            \"type\": \"function\",\n",
    "                            \"function\": {\n",
    "                                \"arguments\": message[\"arguments\"],\n",
    "                                \"name\": message[\"name\"],\n",
    "                            },\n",
    "                        }\n",
    "                    ],\n",
    "                }\n",
    "            ]\n",
    "        elif msg_type == \"message\" and isinstance(message[\"content\"], list):\n",
    "            return [\n",
    "                {\"role\": message[\"role\"], \"content\": content[\"text\"]}\n",
    "                for content in message[\"content\"]\n",
    "            ]\n",
    "        elif msg_type == \"reasoning\":\n",
    "            return [{\"role\": \"assistant\", \"content\": json.dumps(message[\"summary\"])}]\n",
    "        elif msg_type == \"function_call_output\":\n",
    "            return [\n",
    "                {\n",
    "                    \"role\": \"tool\",\n",
    "                    \"content\": message[\"output\"],\n",
    "                    \"tool_call_id\": message[\"call_id\"],\n",
    "                }\n",
    "            ]\n",
    "        compatible_keys = [\"role\", \"content\", \"name\", \"tool_calls\", \"tool_call_id\"]\n",
    "        filtered = {k: v for k, v in message.items() if k in compatible_keys}\n",
    "        return [filtered] if filtered else []\n",
    "\n",
    "    def _prep_msgs_for_cc_llm(self, responses_input) -> list[dict[str, Any]]:\n",
    "        \"Convert from Responses input items to ChatCompletion dictionaries\"\n",
    "        cc_msgs = []\n",
    "        for msg in responses_input:\n",
    "            cc_msgs.extend(self._responses_to_cc(msg.model_dump()))\n",
    "\n",
    "    def _langchain_to_responses(self, messages: list[dict[str, Any]]) -> list[dict[str, Any]]:\n",
    "        \"Convert from ChatCompletion dict to Responses output item dictionaries\"\n",
    "        for message in messages:\n",
    "            message = message.model_dump()\n",
    "            role = message[\"type\"]\n",
    "            if role == \"ai\":\n",
    "                if tool_calls := message.get(\"tool_calls\"):\n",
    "                    return [\n",
    "                        self.create_function_call_item(\n",
    "                            id=message.get(\"id\") or str(uuid4()),\n",
    "                            call_id=tool_call[\"id\"],\n",
    "                            name=tool_call[\"name\"],\n",
    "                            arguments=json.dumps(tool_call[\"args\"]),\n",
    "                        )\n",
    "                        for tool_call in tool_calls\n",
    "                    ]\n",
    "                else:\n",
    "                    return [\n",
    "                        self.create_text_output_item(\n",
    "                            text=message[\"content\"],\n",
    "                            id=message.get(\"id\") or str(uuid4()),\n",
    "                        )\n",
    "                    ]\n",
    "            elif role == \"tool\":\n",
    "                return [\n",
    "                    self.create_function_call_output_item(\n",
    "                        call_id=message[\"tool_call_id\"],\n",
    "                        output=message[\"content\"],\n",
    "                    )\n",
    "                ]\n",
    "            elif role == \"user\":\n",
    "                return [message]\n",
    "\n",
    "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
    "        outputs = [\n",
    "            event.item\n",
    "            for event in self.predict_stream(request)\n",
    "            if event.type == \"response.output_item.done\"\n",
    "        ]\n",
    "        return ResponsesAgentResponse(output=outputs, custom_outputs=request.custom_inputs)\n",
    "\n",
    "    def predict_stream(\n",
    "        self,\n",
    "        request: ResponsesAgentRequest,\n",
    "    ) -> Generator[ResponsesAgentStreamEvent, None, None]:\n",
    "        cc_msgs = []\n",
    "        for msg in request.input:\n",
    "            cc_msgs.extend(self._responses_to_cc(msg.model_dump()))\n",
    "\n",
    "        for event in self.agent.stream({\"messages\": cc_msgs}, stream_mode=[\"updates\", \"messages\"]):\n",
    "            if event[0] == \"updates\":\n",
    "                for node_data in event[1].values():\n",
    "                    for item in self._langchain_to_responses(node_data[\"messages\"]):\n",
    "                        yield ResponsesAgentStreamEvent(type=\"response.output_item.done\", item=item)\n",
    "            # filter the streamed messages to just the generated text messages\n",
    "            elif event[0] == \"messages\":\n",
    "                try:\n",
    "                    chunk = event[1][0]\n",
    "                    if isinstance(chunk, AIMessageChunk) and (content := chunk.content):\n",
    "                        yield ResponsesAgentStreamEvent(\n",
    "                            **self.create_text_delta(delta=content, item_id=chunk.id),\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    print(e)\n",
    "\n",
    "# Create the agent object, and specify it as the agent object to use when\n",
    "# loading the agent back for inference via mlflow.models.set_model()\n",
    "mlflow.langchain.autolog()\n",
    "agent = create_tool_calling_agent(llm, tools, AGENT_SYS_PROMPT)\n",
    "AGENT = LangGraphResponsesAgent(agent)\n",
    "mlflow.models.set_model(AGENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "21e36421-2d91-4858-ace8-dbf9b2ee9886",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from agent import AGENT,agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f898a86-31e8-48c9-9a29-499b47b7584b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, Image,Markdown\n",
    "\n",
    "Image(agent.get_graph().draw_mermaid_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c592890c-8fd2-43ac-a9be-ac14b82210f6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "result = AGENT.predict({\"input\": [{\"role\": \"user\", \"content\": \"How is Nvidia doing and it is worth investing in it or its competitors?\"}]})\n",
    "print(result.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9fdc0421-76b7-4e77-86f2-584b3eb377b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def call_agent(agent, prompt, user_config={\"configurable\": {\"thread_id\": \"any\"}}):\n",
    "    events = agent.stream(\n",
    "        {\"messages\": [{\"role\": \"user\", \"content\": prompt}]},\n",
    "        user_config,\n",
    "        stream_mode=\"values\",\n",
    "    )\n",
    "\n",
    "    for event in events:\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "\n",
    "    print()\n",
    "    print('Final Response:\\n')\n",
    "    display(Markdown(event[\"messages\"][-1].content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ece75a68-b047-491c-a652-e267efc2f86a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "query = 'Get detailed information of how Nvidia and Intel are doing and do a comparative analysis of which stock might be better?'\n",
    "call_agent(agent, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eda949ac-db9a-4d5c-9d7f-716631eb1f83",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for chunk in AGENT.predict_stream(\n",
    "    {\"input\": [{\"role\": \"user\", \"content\": \"Get detailed information of how Nvidia and Intel are doing and do a comparative analysis of which stock might be better?\"}]}\n",
    "):\n",
    "    print(chunk.model_dump(exclude_none=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "69dff97e-65f7-4e7a-a97e-9ed544dc9855",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Log the agent as an MLflow model\n",
    "\n",
    "Log the agent as code from the `agent.py` file. See [MLflow - Models from Code](https://mlflow.org/docs/latest/models.html#models-from-code).\n",
    "\n",
    "### Enable automatic authentication for Databricks resources\n",
    "For the most common Databricks resource types, Databricks supports and recommends declaring resource dependencies for the agent upfront during logging. This enables automatic authentication passthrough when you deploy the agent. With automatic authentication passthrough, Databricks automatically provisions, rotates, and manages short-lived credentials to securely access these resource dependencies from within the agent endpoint.\n",
    "\n",
    "To enable automatic authentication, specify the dependent Databricks resources when calling `mlflow.pyfunc.log_model().`\n",
    "\n",
    "  - **TODO**: If your Unity Catalog tool queries a [vector search index](docs link) or leverages [external functions](docs link), you need to include the dependent vector search index and UC connection objects, respectively, as resources. See docs ([AWS](https://docs.databricks.com/generative-ai/agent-framework/log-agent.html#specify-resources-for-automatic-authentication-passthrough) | [Azure](https://learn.microsoft.com/azure/databricks/generative-ai/agent-framework/log-agent#resources)).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [
    {
     "elements": [
      {
       "dashboardResultIndex": null,
       "elementNUID": "cf007d4c-4412-4109-8f36-7262ce38786c",
       "elementType": "command",
       "guid": "1243a663-d729-4e49-8064-c633acfc0833",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 18,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "99252462-c655-4327-95f0-81e2ff2ca569",
       "elementType": "command",
       "guid": "4a53682e-e413-4e63-8ea7-cd80679e399e",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 42,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "d8e9bef2-8b38-4d84-8b8c-78a8ca93767f",
       "elementType": "command",
       "guid": "96855597-00d7-44d2-bec3-d9d85a2d9eb1",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 90,
        "z": null
       },
       "resultIndex": null
      },
      {
       "dashboardResultIndex": null,
       "elementNUID": "977fa40b-4b2c-4b34-af61-25906e1fdeae",
       "elementType": "command",
       "guid": "d700f3b9-e708-4dea-a84d-0993de1a5d6f",
       "options": null,
       "position": {
        "height": 6,
        "width": 12,
        "x": 0,
        "y": 126,
        "z": null
       },
       "resultIndex": null
      }
     ],
     "globalVars": {},
     "guid": "",
     "layoutOption": {
      "grid": true,
      "stack": true
     },
     "nuid": "5d3cd536-df25-47ed-9d3a-6e4abe57203f",
     "origId": 3106938167386706,
     "title": "Untitled",
     "version": "DashboardViewV1",
     "width": 1024
    }
   ],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "M3_Project_ Build_a_Financial_Analyst_Tool_Use_AI_Agent_with_Databricks",
   "widgets": {}
  },
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
