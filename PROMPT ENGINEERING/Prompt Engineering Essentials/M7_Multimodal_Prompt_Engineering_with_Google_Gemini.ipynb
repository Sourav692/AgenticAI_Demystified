{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yVV6txOmNMn"
   },
   "source": [
    "# Multimodal Prompt Engineering with Google Gemini"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1DnOs6rkbOy"
   },
   "source": [
    "## Overview\n",
    "\n",
    "Gemini 1.5 Flash is a new language model from the Gemini family. This model introduces a breakthrough long context window of up to 1 million tokens that can help seamlessly analyze large amounts of information and long-context understanding. It can process text, images, audio, video, and code all together for deeper insights. Learn more about [Gemini 1.5](https://deepmind.google/technologies/gemini/flash/).\n",
    "\n",
    "Here we will:\n",
    "\n",
    "- analyze images for insights.\n",
    "- analyze audio for insights.\n",
    "- understand videos (including their audio components).\n",
    "- extract information from PDF documents.\n",
    "- process images, video, audio, and text simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "61RBz8LLbxCR"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "No17Cw5hgx12"
   },
   "source": [
    "### Install Google Gen AI library for Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3791,
     "status": "ok",
     "timestamp": 1734092043476,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "tFy3H3aPgx12",
    "outputId": "f5230878-428c-419b-926e-078d40a696b0"
   },
   "outputs": [],
   "source": [
    "!pip install google-generativeai==0.8.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PtBa7rlWJWH3"
   },
   "source": [
    "## Enter API Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9300,
     "status": "ok",
     "timestamp": 1734092052772,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "Av1UpSgXZUsI",
    "outputId": "621c571a-b9de-4964-b40e-39c976f5da17"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "GOOGLE_API_KEY = getpass('Enter Gemini API Key:')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jXHfaVS66_01"
   },
   "source": [
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 514
    },
    "executionInfo": {
     "elapsed": 5908,
     "status": "ok",
     "timestamp": 1734092060557,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "lslYAvw37JGQ",
    "outputId": "a83fc6cc-e97f-4b21-d969-ebee74c93eab"
   },
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "for m in genai.list_models():\n",
    "  if 'generateContent' in m.supported_generation_methods:\n",
    "    print(m.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BY1nfXrqRxVX"
   },
   "source": [
    "### Load the Gemini 1.5 Flash model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1734092063620,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "U7ExWmuLBdIA"
   },
   "outputs": [],
   "source": [
    "generation_config = genai.types.GenerationConfig(\n",
    "    temperature=0\n",
    ")\n",
    "gemini = genai.GenerativeModel(model_name='gemini-1.5-flash-latest',\n",
    "                               generation_config=generation_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9OKM0-4SQf8"
   },
   "source": [
    "### LLM basic usage\n",
    "\n",
    "Below is a simple example that demonstrates how to prompt the Gemini 1.5 Flash model using the API. Learn more about the [Gemini API parameters](https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/gemini#gemini-pro)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "executionInfo": {
     "elapsed": 2678,
     "status": "ok",
     "timestamp": 1734092068068,
     "user": {
      "displayName": "Dipanjan “DJ” Sarkar",
      "userId": "05135987707016476934"
     },
     "user_tz": -330
    },
    "id": "FhFxrtfdSwOP",
    "outputId": "7f76dc4a-c9ec-4451-9076-9f8a2f1ccd8c"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "prompt = \"\"\"\n",
    "  Explain what is Generative AI in 3 bullet points\n",
    "\"\"\"\n",
    "\n",
    "response = gemini.generate_content(contents=prompt)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CqbsC7LHA_qB"
   },
   "source": [
    "## Image Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iESsxr9bBBhg",
    "outputId": "9ced29b7-8390-4d34-c82c-dd69fba27436"
   },
   "outputs": [],
   "source": [
    "# download images using curl\n",
    "!curl https://i.imgur.com/6b9jwkk.png -o image1.png\n",
    "!curl https://i.imgur.com/9CWuU2q.png -o image2.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "g7LHLGWEBOgt",
    "outputId": "bd216bd8-3d82-46bd-f18d-e266de7295e8"
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image as ImageDisp, display\n",
    "\n",
    "display(ImageDisp('image1.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "YTO4T2eMBYRL",
    "outputId": "0f4cc0c9-a533-4a02-ac37-af34a0e63ccb"
   },
   "outputs": [],
   "source": [
    "display(ImageDisp('image2.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b98gVHBoCY6o"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "image1 = Image.open('image1.png')\n",
    "image2 = Image.open('image2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "id": "WJOhxB0RBa4A",
    "outputId": "c30bb316-4681-4fcd-e07e-6a8f427c4dc5"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Given the following images which can contain graphs, tables and text,\n",
    "  analyze all of them to answer the following question:\n",
    "\n",
    "  Tell me about the top 5 years with largest Wildfires\n",
    "\"\"\"\n",
    "\n",
    "contents = [image1, image2,  prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 296
    },
    "id": "p1im43NQCkx1",
    "outputId": "e6253a55-d585-402f-cbfd-65323ddb97ea"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Given the following images which can contain graphs, tables and text,\n",
    "  analyze all of them to answer the following question:\n",
    "\n",
    "  Tell me about trend of wildfires in terms of acreage burned by region and ownership\n",
    "\"\"\"\n",
    "\n",
    "contents = [image1, image2,  prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9HTEdrOm_Ie0"
   },
   "source": [
    "## PDF Doc Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8_wpUGR8_NCO",
    "outputId": "7949609c-d7dc-4630-aa5e-9194afd5052c"
   },
   "outputs": [],
   "source": [
    "!wget https://sgp.fas.org/crs/misc/IF10244.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "id": "KOXNdYMX_Opk",
    "outputId": "2c87b8f7-9918-4f6a-d7ed-51300c9cf491"
   },
   "outputs": [],
   "source": [
    "pdf_ref = genai.upload_file(path='./IF10244.pdf')\n",
    "pdf_ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 203
    },
    "id": "i7tED33A_WpZ",
    "outputId": "de0333c1-58c9-4cc6-de40-3efbe739c466"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Given the PDF file, use it to answer the following question:\n",
    "\n",
    "  Tell me about the top 5 years with largest Wildfires\n",
    "\"\"\"\n",
    "\n",
    "contents = [pdf_ref, prompt]\n",
    "\n",
    "response = gemini.generate_content(contents)\n",
    "\n",
    "Markdown(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "acRxKRA-sr0j"
   },
   "source": [
    "## Audio understanding\n",
    "\n",
    "Gemini 1.5 Flash can directly process audio for long-context understanding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GVQjZP5TJB1A",
    "outputId": "5d7dee6c-1da0-4fe7-ca35-5f1ad9360420"
   },
   "outputs": [],
   "source": [
    "!wget \"https://storage.googleapis.com/cloud-samples-data/generative-ai/audio/pixel.mp3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "bLo6yj_pJMHl",
    "outputId": "3e91ed67-752c-40ac-90af-41586036b78e"
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "\n",
    "IPython.display.Audio('./pixel.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndrrPztwImLO"
   },
   "outputs": [],
   "source": [
    "audio_file = genai.upload_file(path='./pixel.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wC6bkr8uJani",
    "outputId": "7f2f54b6-180b-4e9e-8654-c56669df676e"
   },
   "outputs": [],
   "source": [
    "audio_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sXM19QQ4vj1"
   },
   "source": [
    "#### Example 1: Title Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "OPQ1fBk44E6L",
    "outputId": "0e9931c3-e596-49cc-8a8c-61e886d33749"
   },
   "outputs": [],
   "source": [
    "\n",
    "prompt = \"\"\"\n",
    "  Please provide a summary for the audio.\n",
    "  Provide chapter titles with timestamps, be concise and short, no need to provide chapter summaries.\n",
    "  Do not make up any information that is not part of the audio and do not be verbose.\n",
    "\"\"\"\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "response = gemini.generate_content(contents=contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzA8vKgQATGL"
   },
   "source": [
    "#### Example 2: Transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "qT2T602zr7bB",
    "outputId": "bd24ec0f-fc11-41ec-f9e7-c830913f3eaa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Can you transcribe this interview, in the format of [timecode] - [speaker] : caption.\n",
    "    Use speaker A, speaker B, etc. to identify the speakers. Map each speaker to their real name at the start of the output\n",
    "    Each speaker should have a single caption based on their starting timestamp\n",
    "    Do not break up the transcript into multiple timestamps for the same speaker\n",
    "    Show the output only for the part of the conversation about the pixel watch and follow the format mentioned above for the output\n",
    "\"\"\"\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "response = gemini.generate_content(contents=contents)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RX3HgFTf6CLq"
   },
   "source": [
    "#### Example 3: Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "wg0Mj8pj5i24",
    "outputId": "a0d4ed88-8e2d-43ca-fae4-d69933fe8332"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "    Given the audio file, generate a comprehensive summary of:\n",
    "     - Key Speakers\n",
    "     - Key products and features discussed\n",
    "     - Any other noteworthy discussions\n",
    "\"\"\"\n",
    "\n",
    "contents = [audio_file, prompt]\n",
    "response = gemini.generate_content(contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U36v4TmswAG"
   },
   "source": [
    "## Video with audio understanding\n",
    "\n",
    "Try out Gemini 1.5 Flash’s native multimodal and long context capabilities on video interleaving with audio inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_dhz1guhL-Io",
    "outputId": "81eda92b-d5b7-40d9-bed8-a4f70127fc34"
   },
   "outputs": [],
   "source": [
    "!wget \"https://storage.googleapis.com/cloud-samples-data/generative-ai/video/pixel8.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "EDswcPI0tSRk",
    "outputId": "c0aed7eb-7acb-4e15-f2ac-df174756abe1"
   },
   "outputs": [],
   "source": [
    "IPython.display.Video('pixel8.mp4', embed=True, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IpBBFMWpMfT9"
   },
   "outputs": [],
   "source": [
    "video_file = genai.upload_file(path='./pixel8.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "R9isZfjzCYxw",
    "outputId": "ab4b5277-8bb0-4731-9e11-92b7069b1f52"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Provide a comprehensive summary of the video.\n",
    "  The summary should also contain anything important which people discuss in the video.\n",
    "\"\"\"\n",
    "\n",
    "contents = [video_file, prompt]\n",
    "\n",
    "response = gemini.generate_content(contents=contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pC1vS-5Jinbi",
    "outputId": "9636b086-e0d8-4df8-c63b-9d82d37ac206"
   },
   "outputs": [],
   "source": [
    "!gdown -O 'awsq_video.mp4' '1shnBXeuXYcbRr9IhxofHkT3rlSaqPG1e'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 274
    },
    "id": "lkF3JCnur7bC",
    "outputId": "3c3bff17-19e9-48ca-f51f-1f3a949ae2a8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "IPython.display.Video('awsq_video.mp4', embed=True, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mZVzpiAqr7bC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "vid = genai.upload_file(path='./awsq_video.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "id": "hHifGyler7bC",
    "outputId": "521b495d-d501-433f-9ecb-9418eed9a0fa",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Provide a description of the video.\n",
    "  The description should cover the key steps covered in the video in bullet points\n",
    "\"\"\"\n",
    "\n",
    "contents = [vid, prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcBZZ-bJe2yS"
   },
   "source": [
    "Gemini 1.5 Pro model is able to process the video with audio, retrieve and extract textual and audio information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3vu8ogWs7iZ"
   },
   "source": [
    "## All modalities (images, video, audio, text) at once\n",
    "\n",
    "Gemini 1.5 Pro is natively multimodal and supports interleaving of data from different modalities, it can support a mix of audio, visual, text, and\n",
    "code inputs in the same input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0htbobb4SDuD",
    "outputId": "34592a12-f751-4a1a-8183-7c7a49b5ffc0"
   },
   "outputs": [],
   "source": [
    "!wget 'https://storage.googleapis.com/cloud-samples-data/generative-ai/video/behind_the_scenes_pixel.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjXmyyJ8UaDi",
    "outputId": "48ee3c33-019b-4972-b08c-c18c0cb83615"
   },
   "outputs": [],
   "source": [
    "!wget 'https://storage.googleapis.com/cloud-samples-data/generative-ai/image/a-man-and-a-dog.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "qS7KSwvbjhFh",
    "outputId": "80a9a50c-c371-4583-d4d1-3884545396ce"
   },
   "outputs": [],
   "source": [
    "IPython.display.Image('a-man-and-a-dog.png', width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cASz2BFlUj96"
   },
   "outputs": [],
   "source": [
    "video_file = genai.upload_file(path='./behind_the_scenes_pixel.mp4')\n",
    "image_file = genai.upload_file(path='./a-man-and-a-dog.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 139
    },
    "id": "pRdzwDi9iLGn",
    "outputId": "51e6d9e4-9823-4a57-8a5c-50f3b5c568a8"
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "  Look through each frame in the video carefully and answer the questions.\n",
    "  Only base your answers strictly on what information is available in the video attached.\n",
    "  Do not make up any information that is not part of the video and summarize your answer\n",
    "  in three bullet points max\n",
    "\n",
    "  Questions:\n",
    "  - When is the moment in the image happening in the video? Provide a timestamp.\n",
    "  - What is the context of the moment and what does the narrator say about it?\n",
    "\"\"\"\n",
    "\n",
    "contents = [video_file, image_file, prompt]\n",
    "response = gemini.generate_content(contents)\n",
    "display(Markdown(response.text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3iovYxOwOT7"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "In this tutorial, you've learned how to use the Gemini 1.5 Flash to:\n",
    "\n",
    "- analyze images for insights.\n",
    "- analyze PDF docs for insights.\n",
    "- analyze audio for insights.\n",
    "- understand videos (including their audio components).\n",
    "- process images, video, audio, and text simultaneously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JcduiYrmVaHb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m120",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m120"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
